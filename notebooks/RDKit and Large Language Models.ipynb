{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4549116e",
   "metadata": {},
   "source": [
    "# What is this post?\n",
    "\n",
    "On the bus to the CADD GRC, Nadine suggested that I try using Copilot to generate ideas for an RDKit blog post. It seemed like an interesting experiment and I'm heading out for a couple of weeks of vacation, so I thought I'd go ahead and give it a try. This post is the result.\n",
    "\n",
    "What's below is the result of a chat session with Copilot, using Claude Sonnet 4. The initial prompt was: `suggest a topic for a new RDKit blog post`. I made a couple of small edits at the very end, but otherwise the text is exactly as generated by the LLM. I hope to come back to this at some point in the future and dig into the code and content in detail, but right now I need to go pack my gear to head to the mountains for a couple of weeks of climbing and mountaineering.\n",
    "\n",
    "The actual chat session is [available here]().\n",
    "\n",
    "I'm going to go ahead and upload this and post it sometime around July 31st (or whenever I have decent internet access). There won't be a new blog post next week, but I will be back the week of August 11th."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff834d8b",
   "metadata": {},
   "source": [
    "# RDKit and Large Language Models: Chemical Structure-Text Integration in the AI Era\n",
    "\n",
    "The landscape of artificial intelligence has been dramatically transformed by the rise of large language models (LLMs), and the field of chemistry is no exception. From GPT-4's ability to reason about molecular structures to specialized chemistry-focused models like ChemCrow and Galactica, we're witnessing an unprecedented convergence of natural language processing and chemical informatics. This presents both exciting opportunities and unique challenges for computational chemists and cheminformatics practitioners.\n",
    "\n",
    "The RDKit, as one of the most widely-used open-source cheminformatics toolkits, finds itself at a fascinating intersection in this new landscape. While LLMs excel at processing and generating text-based representations of chemical knowledge, they often struggle with the precise, structure-based reasoning that is second nature to dedicated cheminformatics tools. Conversely, traditional cheminformatics approaches excel at molecular manipulation and property calculation but have limited ability to understand and generate natural language descriptions of chemical concepts.\n",
    "\n",
    "This complementary relationship suggests powerful synergies. LLMs can help democratize access to chemical knowledge by translating between technical chemical representations and human-readable explanations. Meanwhile, tools like RDKit provide the essential chemical \"reality check\" - validating molecular structures, calculating properties, and ensuring that AI-generated chemistry actually makes sense from a chemical perspective.\n",
    "\n",
    "In this post, we'll explore practical approaches for integrating RDKit with modern LLM workflows. We'll cover how to:\n",
    "\n",
    "- Use RDKit to validate and process chemical structures generated by LLMs\n",
    "- Convert RDKit molecular representations into rich text descriptions suitable for training or prompting LLMs\n",
    "- Build robust pipelines that combine the strengths of both approaches\n",
    "- Handle the unique challenges that arise when bridging symbolic chemical representations with statistical language models\n",
    "\n",
    "The goal is not to replace either approach, but rather to show how they can work together to create more powerful, reliable, and accessible chemical AI systems. Whether you're building a chemical chatbot, curating training data for a chemistry-focused LLM, or simply trying to make your chemical data more searchable and interpretable, the patterns we'll explore should provide a solid foundation.\n",
    "\n",
    "Let's start by setting up our environment and exploring some basic integration patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1759d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit version: 2025.03.4\n",
      "Generated: Sat Jul 26 09:53:54 2025\n"
     ]
    }
   ],
   "source": [
    "# Standard RDKit imports\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors, rdMolDescriptors\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import rdBase\n",
    "import time\n",
    "\n",
    "print(f\"RDKit version: {rdBase.rdkitVersion}\")\n",
    "print(f\"Generated: {time.asctime()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168a2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for LLM integration examples\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b343fb",
   "metadata": {},
   "source": [
    "# Structure Validation: RDKit as the Chemical Reality Check\n",
    "\n",
    "One of the most immediate and practical applications of RDKit in LLM workflows is structure validation. LLMs, while impressive at generating chemical-looking text, often produce invalid SMILES strings, impossible molecular structures, or chemically nonsensical compounds. RDKit provides robust validation capabilities that can catch these errors and provide meaningful feedback.\n",
    "\n",
    "Let's explore some common validation scenarios and how to handle them systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7a2e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES Validation Examples:\n",
      "==================================================\n",
      "\n",
      "SMILES: CCO\n",
      "Valid: True\n",
      "Canonical: CCO\n",
      "Properties: 3 atoms, MW=46.1\n",
      "\n",
      "SMILES: c1ccccc1\n",
      "Valid: True\n",
      "Canonical: c1ccccc1\n",
      "Properties: 6 atoms, MW=78.1\n",
      "\n",
      "SMILES: C[C@H](N)C(=O)O\n",
      "Valid: True\n",
      "Canonical: C[C@H](N)C(=O)O\n",
      "Properties: 6 atoms, MW=89.1\n",
      "\n",
      "SMILES: CCO[invalid]\n",
      "Valid: False\n",
      "Errors: Invalid SMILES: Could not parse structure\n",
      "\n",
      "SMILES: C1CCC\n",
      "Valid: False\n",
      "Errors: Invalid SMILES: Could not parse structure\n",
      "\n",
      "SMILES: C(C)(C)(C)(C)C\n",
      "Valid: False\n",
      "Errors: Invalid SMILES: Could not parse structure\n",
      "\n",
      "SMILES: \n",
      "Valid: False\n",
      "Errors: Empty molecule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:53:54] SMILES Parse Error: syntax error while parsing: CCO[invalid]\n",
      "[09:53:54] SMILES Parse Error: check for mistakes around position 5:\n",
      "[09:53:54] CCO[invalid]\n",
      "[09:53:54] ~~~~^\n",
      "[09:53:54] SMILES Parse Error: Failed parsing SMILES 'CCO[invalid]' for input: 'CCO[invalid]'\n",
      "[09:53:54] SMILES Parse Error: unclosed ring for input: 'C1CCC'\n",
      "[09:53:54] Explicit valence for atom # 0 C, 5, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "def validate_smiles_with_details(smiles: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Comprehensive SMILES validation with detailed feedback.\n",
    "    Returns a dictionary with validation results and diagnostic information.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'smiles': smiles,\n",
    "        'is_valid': False,\n",
    "        'mol': None,\n",
    "        'canonical_smiles': None,\n",
    "        'errors': [],\n",
    "        'warnings': [],\n",
    "        'properties': {}\n",
    "    }\n",
    "    \n",
    "    # Basic parsing\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            result['errors'].append(\"Invalid SMILES: Could not parse structure\")\n",
    "            return result\n",
    "        \n",
    "        result['mol'] = mol\n",
    "        result['is_valid'] = True\n",
    "        \n",
    "        # Get canonical SMILES\n",
    "        try:\n",
    "            result['canonical_smiles'] = Chem.MolToSmiles(mol)\n",
    "        except:\n",
    "            result['warnings'].append(\"Could not generate canonical SMILES\")\n",
    "        \n",
    "        # Basic chemical checks\n",
    "        num_atoms = mol.GetNumAtoms()\n",
    "        if num_atoms == 0:\n",
    "            result['errors'].append(\"Empty molecule\")\n",
    "            result['is_valid'] = False\n",
    "        elif num_atoms > 200:\n",
    "            result['warnings'].append(f\"Very large molecule ({num_atoms} atoms)\")\n",
    "        \n",
    "        # Check for unusual valences\n",
    "        try:\n",
    "            Chem.SanitizeMol(mol)\n",
    "        except Exception as e:\n",
    "            result['errors'].append(f\"Sanitization failed: {str(e)}\")\n",
    "            result['is_valid'] = False\n",
    "        \n",
    "        # Calculate basic properties if valid\n",
    "        if result['is_valid']:\n",
    "            try:\n",
    "                result['properties'] = {\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'num_bonds': mol.GetNumBonds(),\n",
    "                    'molecular_weight': Descriptors.MolWt(mol),\n",
    "                    'num_rings': rdMolDescriptors.CalcNumRings(mol),\n",
    "                    'num_aromatic_rings': rdMolDescriptors.CalcNumAromaticRings(mol)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                result['warnings'].append(f\"Property calculation failed: {str(e)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['errors'].append(f\"Parsing error: {str(e)}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the function with some examples\n",
    "test_smiles = [\n",
    "    \"CCO\",  # ethanol - valid\n",
    "    \"c1ccccc1\",  # benzene - valid\n",
    "    \"C[C@H](N)C(=O)O\",  # alanine - valid with stereochemistry\n",
    "    \"CCO[invalid]\",  # invalid SMILES\n",
    "    \"C1CCC\",  # invalid - unclosed ring\n",
    "    \"C(C)(C)(C)(C)C\",  # carbon with too many bonds\n",
    "    \"\",  # empty string\n",
    "]\n",
    "\n",
    "print(\"SMILES Validation Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for smiles in test_smiles:\n",
    "    result = validate_smiles_with_details(smiles)\n",
    "    print(f\"\\nSMILES: {smiles}\")\n",
    "    print(f\"Valid: {result['is_valid']}\")\n",
    "    if result['canonical_smiles']:\n",
    "        print(f\"Canonical: {result['canonical_smiles']}\")\n",
    "    if result['errors']:\n",
    "        print(f\"Errors: {', '.join(result['errors'])}\")\n",
    "    if result['warnings']:\n",
    "        print(f\"Warnings: {', '.join(result['warnings'])}\")\n",
    "    if result['properties']:\n",
    "        props = result['properties']\n",
    "        print(f\"Properties: {props['num_atoms']} atoms, MW={props['molecular_weight']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279c006",
   "metadata": {},
   "source": [
    "## Batch Validation for LLM Outputs\n",
    "\n",
    "When working with LLMs that generate multiple chemical structures, you'll often need to validate batches of SMILES strings. Here's a more robust approach that can handle large datasets efficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bab073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch of LLM-generated SMILES...\n",
      "\n",
      "Batch Validation Summary:\n",
      "Total structures: 10\n",
      "Valid structures: 9\n",
      "Invalid structures: 1\n",
      "Structures with warnings: 0\n",
      "\n",
      "Detailed Results:\n",
      "                 input_smiles  is_valid           canonical_smiles  molecular_weight  num_atoms\n",
      "CC(C)CC1=CC=C(C=C1)C(C)C(=O)O      True CC(C)Cc1ccc(C(C)C(=O)O)cc1           206.285       15.0\n",
      "          C1=CC=C(C=C1)C(=O)O      True             O=C(O)c1ccccc1           122.123        9.0\n",
      "             invalidsmiles123     False                       None               NaN        NaN\n",
      "                  C1=CC=CC=C1      True                   c1ccccc1            78.114        6.0\n",
      "                          CCO      True                        CCO            46.069        3.0\n",
      "              C[C@H](N)C(=O)O      True            C[C@H](N)C(=O)O            89.094        6.0\n",
      "                      C1CCC1C      True                    CC1CCC1            70.135        5.0\n",
      "             c1ccccc1c2ccccc2      True        c1ccc(-c2ccccc2)cc1           154.212       12.0\n",
      "            CCCCCCCCCCCCCCCCO      True          CCCCCCCCCCCCCCCCO           242.447       17.0\n",
      "        C1=CC=C2C(=C1)C=CC=C2      True             c1ccc2ccccc2c1           128.174       10.0\n",
      "\n",
      "Error Details for Invalid Structures:\n",
      "'invalidsmiles123': Invalid SMILES: Could not parse structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:53:54] SMILES Parse Error: syntax error while parsing: invalidsmiles123\n",
      "[09:53:54] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:54] invalidsmiles123\n",
      "[09:53:54] ^\n",
      "[09:53:54] SMILES Parse Error: Failed parsing SMILES 'invalidsmiles123' for input: 'invalidsmiles123'\n"
     ]
    }
   ],
   "source": [
    "def batch_validate_structures(smiles_list: List[str], \n",
    "                             include_properties: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Validate a batch of SMILES strings and return results as a DataFrame.\n",
    "    Useful for processing LLM outputs or curating chemical datasets.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        result = validate_smiles_with_details(smiles)\n",
    "        \n",
    "        # Flatten the result for DataFrame storage\n",
    "        row = {\n",
    "            'index': i,\n",
    "            'input_smiles': smiles,\n",
    "            'is_valid': result['is_valid'],\n",
    "            'canonical_smiles': result['canonical_smiles'],\n",
    "            'num_errors': len(result['errors']),\n",
    "            'num_warnings': len(result['warnings']),\n",
    "            'error_messages': '; '.join(result['errors']) if result['errors'] else None,\n",
    "            'warning_messages': '; '.join(result['warnings']) if result['warnings'] else None\n",
    "        }\n",
    "        \n",
    "        # Add properties if requested and available\n",
    "        if include_properties and result['properties']:\n",
    "            row.update(result['properties'])\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Simulate some LLM-generated SMILES (mix of valid and invalid)\n",
    "llm_generated_smiles = [\n",
    "    \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",  # ibuprofen-like\n",
    "    \"C1=CC=C(C=C1)C(=O)O\",  # benzoic acid\n",
    "    \"invalidsmiles123\",  # clearly invalid\n",
    "    \"C1=CC=CC=C1\",  # benzene\n",
    "    \"CCO\",  # ethanol\n",
    "    \"C[C@H](N)C(=O)O\",  # L-alanine\n",
    "    \"C1CCC1C\",  # methylcyclopropane\n",
    "    \"c1ccccc1c2ccccc2\",  # biphenyl\n",
    "    \"CCCCCCCCCCCCCCCCO\",  # long-chain alcohol\n",
    "    \"C1=CC=C2C(=C1)C=CC=C2\",  # naphthalene\n",
    "]\n",
    "\n",
    "print(\"Processing batch of LLM-generated SMILES...\")\n",
    "df_results = batch_validate_structures(llm_generated_smiles)\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"\\nBatch Validation Summary:\")\n",
    "print(f\"Total structures: {len(df_results)}\")\n",
    "print(f\"Valid structures: {df_results['is_valid'].sum()}\")\n",
    "print(f\"Invalid structures: {(~df_results['is_valid']).sum()}\")\n",
    "print(f\"Structures with warnings: {(df_results['num_warnings'] > 0).sum()}\")\n",
    "\n",
    "# Show the results table\n",
    "print(f\"\\nDetailed Results:\")\n",
    "display_cols = ['input_smiles', 'is_valid', 'canonical_smiles', 'molecular_weight', 'num_atoms']\n",
    "available_cols = [col for col in display_cols if col in df_results.columns]\n",
    "print(df_results[available_cols].to_string(index=False))\n",
    "\n",
    "# Show error details for invalid structures\n",
    "invalid_structures = df_results[~df_results['is_valid']]\n",
    "if len(invalid_structures) > 0:\n",
    "    print(f\"\\nError Details for Invalid Structures:\")\n",
    "    for _, row in invalid_structures.iterrows():\n",
    "        print(f\"'{row['input_smiles']}': {row['error_messages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b8813d",
   "metadata": {},
   "source": [
    "## Chemical Plausibility Checks\n",
    "\n",
    "Beyond basic SMILES validation, we can implement more sophisticated checks to assess whether LLM-generated structures are chemically reasonable. This is particularly important because LLMs might generate syntactically valid but chemically implausible structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deaf8036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Plausibility Assessment:\n",
      "==================================================\n",
      "\n",
      "Molecule: Simple alcohol\n",
      "SMILES: CCO\n",
      "Plausible: True\n",
      "Properties: MW=46.1, Rings=0, LogP=-0.00, Lipinski violations=0\n",
      "\n",
      "Molecule: Ibuprofen\n",
      "SMILES: CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\n",
      "Plausible: True\n",
      "Properties: MW=206.3, Rings=1, LogP=3.07, Lipinski violations=0\n",
      "\n",
      "Molecule: Very long alkyl chain\n",
      "SMILES: CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "Plausible: True\n",
      "Warnings: Very high LogP: 19.75; Multiple Lipinski violations: ['MW > 500', 'LogP > 5']\n",
      "Properties: MW=703.4, Rings=0, LogP=19.75, Lipinski violations=2\n",
      "\n",
      "Molecule: Long fatty acid\n",
      "SMILES: CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC(=O)O\n",
      "Plausible: True\n",
      "Warnings: Very high LogP: 11.40\n",
      "Properties: MW=466.8, Rings=0, LogP=11.40, Lipinski violations=1\n",
      "\n",
      "Molecule: Anthracene (PAH)\n",
      "SMILES: c1ccc2c(c1)c3ccccc3c4ccccc24\n",
      "Plausible: True\n",
      "Properties: MW=228.3, Rings=4, LogP=5.15, Lipinski violations=1\n"
     ]
    }
   ],
   "source": [
    "def assess_chemical_plausibility(mol: Chem.Mol) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Assess the chemical plausibility of a molecule beyond basic validation.\n",
    "    Returns flags for potential issues that might indicate AI-generated artifacts.\n",
    "    \"\"\"\n",
    "    if mol is None:\n",
    "        return {'plausible': False, 'issues': ['Invalid molecule']}\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Molecular weight checks\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    if mw < 16:  # Lighter than methane\n",
    "        issues.append(f\"Extremely low molecular weight: {mw:.1f}\")\n",
    "    elif mw > 2000:  # Very large for small molecule\n",
    "        warnings.append(f\"Very high molecular weight: {mw:.1f}\")\n",
    "    \n",
    "    # Atom count checks\n",
    "    num_atoms = mol.GetNumAtoms()\n",
    "    if num_atoms > 150:  # Unusually large for typical organic molecules\n",
    "        warnings.append(f\"Very large molecule: {num_atoms} atoms\")\n",
    "    \n",
    "    # Check for unusual atom types in organic chemistry context\n",
    "    unusual_atoms = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        symbol = atom.GetSymbol()\n",
    "        if symbol not in ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'H']:\n",
    "            unusual_atoms.append(symbol)\n",
    "    \n",
    "    if unusual_atoms:\n",
    "        warnings.append(f\"Unusual atoms present: {set(unusual_atoms)}\")\n",
    "    \n",
    "    # Check carbon-to-heteroatom ratio\n",
    "    carbon_count = sum(1 for atom in mol.GetAtoms() if atom.GetSymbol() == 'C')\n",
    "    heteroatom_count = sum(1 for atom in mol.GetAtoms() if atom.GetSymbol() not in ['C', 'H'])\n",
    "    \n",
    "    if heteroatom_count > 0:\n",
    "        c_to_hetero_ratio = carbon_count / heteroatom_count\n",
    "        if c_to_hetero_ratio < 0.1:  # Too many heteroatoms\n",
    "            warnings.append(f\"Unusual C:heteroatom ratio: {c_to_hetero_ratio:.2f}\")\n",
    "    \n",
    "    # Check for overly complex ring systems\n",
    "    ring_info = mol.GetRingInfo()\n",
    "    num_rings = ring_info.NumRings()\n",
    "    if num_rings > 10:  # Many fused rings might be suspicious\n",
    "        warnings.append(f\"Complex ring system: {num_rings} rings\")\n",
    "    \n",
    "    # Check for extremely high or low LogP (rough estimate)\n",
    "    try:\n",
    "        logp = Descriptors.MolLogP(mol)\n",
    "        if logp > 8:\n",
    "            warnings.append(f\"Very high LogP: {logp:.2f}\")\n",
    "        elif logp < -5:\n",
    "            warnings.append(f\"Very low LogP: {logp:.2f}\")\n",
    "    except:\n",
    "        warnings.append(\"Could not calculate LogP\")\n",
    "    \n",
    "    # Check for drug-likeness violations (Lipinski's Rule of Five)\n",
    "    violations = []\n",
    "    if mw > 500:\n",
    "        violations.append(\"MW > 500\")\n",
    "    if Descriptors.MolLogP(mol) > 5:\n",
    "        violations.append(\"LogP > 5\")\n",
    "    if Descriptors.NumHDonors(mol) > 5:\n",
    "        violations.append(\"H-donors > 5\")\n",
    "    if Descriptors.NumHAcceptors(mol) > 10:\n",
    "        violations.append(\"H-acceptors > 10\")\n",
    "    \n",
    "    if len(violations) >= 2:  # Allow one violation\n",
    "        warnings.append(f\"Multiple Lipinski violations: {violations}\")\n",
    "    \n",
    "    return {\n",
    "        'plausible': len(issues) == 0,\n",
    "        'issues': issues,\n",
    "        'warnings': warnings,\n",
    "        'properties': {\n",
    "            'molecular_weight': mw,\n",
    "            'num_atoms': num_atoms,\n",
    "            'num_rings': num_rings,\n",
    "            'logp': Descriptors.MolLogP(mol) if mol else None,\n",
    "            'lipinski_violations': len(violations)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test with some examples\n",
    "test_molecules = [\n",
    "    (\"CCO\", \"Simple alcohol\"),\n",
    "    (\"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\", \"Ibuprofen\"),\n",
    "    (\"C\" * 50, \"Very long alkyl chain\"),  # Unusual but valid\n",
    "    (\"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC(=O)O\", \"Long fatty acid\"),\n",
    "    (\"c1ccc2c(c1)c3ccccc3c4ccccc24\", \"Anthracene (PAH)\"),\n",
    "]\n",
    "\n",
    "print(\"Chemical Plausibility Assessment:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for smiles, description in test_molecules:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    assessment = assess_chemical_plausibility(mol)\n",
    "    \n",
    "    print(f\"\\nMolecule: {description}\")\n",
    "    print(f\"SMILES: {smiles}\")\n",
    "    print(f\"Plausible: {assessment['plausible']}\")\n",
    "    \n",
    "    if assessment['issues']:\n",
    "        print(f\"Issues: {'; '.join(assessment['issues'])}\")\n",
    "    if assessment['warnings']:\n",
    "        print(f\"Warnings: {'; '.join(assessment['warnings'])}\")\n",
    "    \n",
    "    props = assessment['properties']\n",
    "    print(f\"Properties: MW={props['molecular_weight']:.1f}, \"\n",
    "          f\"Rings={props['num_rings']}, \"\n",
    "          f\"LogP={props['logp']:.2f}, \"\n",
    "          f\"Lipinski violations={props['lipinski_violations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e13a5b",
   "metadata": {},
   "source": [
    "## Putting It Together: A Complete Validation Pipeline\n",
    "\n",
    "Here's how you might integrate these validation functions into a complete pipeline for processing LLM-generated chemical structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091dc7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Chemical Validator Demo\n",
      "========================================\n",
      "Testing with Normal Mode:\n",
      "Input structures: 10\n",
      "Structures passing validation: 7\n",
      "\n",
      "Passed structures:\n",
      "1. CCO\n",
      "2. CC(C)Cc1ccc(C(C)C(=O)O)cc1\n",
      "3. c1ccccc1\n",
      "4. CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "5. O=C(O)c1ccccc1\n",
      "6. C[C@H](N)C(=O)O\n",
      "7. CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "Validation Report:\n",
      "==================\n",
      "Total structures processed: 10\n",
      "Valid SMILES: 7 (70.0%)\n",
      "Chemically plausible: 7 (70.0%)\n",
      "Passed all filters: 7 (70.0%)\n",
      "\n",
      "Success rate: 70.0%\n",
      "\n",
      "========================================\n",
      "Testing with Strict Mode:\n",
      "Structures passing strict validation: 5\n",
      "Validation Report:\n",
      "==================\n",
      "Total structures processed: 10\n",
      "Valid SMILES: 7 (70.0%)\n",
      "Chemically plausible: 7 (70.0%)\n",
      "Passed all filters: 5 (50.0%)\n",
      "\n",
      "Success rate: 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:53:54] SMILES Parse Error: syntax error while parsing: invalidsmiles\n",
      "[09:53:54] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:54] invalidsmiles\n",
      "[09:53:54] ^\n",
      "[09:53:54] SMILES Parse Error: Failed parsing SMILES 'invalidsmiles' for input: 'invalidsmiles'\n",
      "[09:53:54] SMILES Parse Error: unclosed ring for input: 'C1CCC'\n",
      "[09:53:54] Explicit valence for atom # 1 C, 6, is greater than permitted\n",
      "[09:53:54] SMILES Parse Error: syntax error while parsing: invalidsmiles\n",
      "[09:53:54] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:54] invalidsmiles\n",
      "[09:53:54] ^\n",
      "[09:53:54] SMILES Parse Error: Failed parsing SMILES 'invalidsmiles' for input: 'invalidsmiles'\n",
      "[09:53:54] SMILES Parse Error: unclosed ring for input: 'C1CCC'\n",
      "[09:53:54] Explicit valence for atom # 1 C, 6, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "class LLMChemicalValidator:\n",
    "    \"\"\"\n",
    "    A comprehensive validator for LLM-generated chemical structures.\n",
    "    Combines SMILES validation, chemical plausibility checks, and filtering.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, strict_mode: bool = False):\n",
    "        self.strict_mode = strict_mode\n",
    "        self.validation_stats = {\n",
    "            'total_processed': 0,\n",
    "            'valid_smiles': 0,\n",
    "            'chemically_plausible': 0,\n",
    "            'passed_filters': 0\n",
    "        }\n",
    "    \n",
    "    def validate_structure(self, smiles: str) -> Dict[str, any]:\n",
    "        \"\"\"Validate a single SMILES string with full analysis.\"\"\"\n",
    "        result = validate_smiles_with_details(smiles)\n",
    "        \n",
    "        if result['is_valid'] and result['mol']:\n",
    "            # Add plausibility assessment\n",
    "            plausibility = assess_chemical_plausibility(result['mol'])\n",
    "            result['plausibility'] = plausibility\n",
    "            result['chemically_plausible'] = plausibility['plausible']\n",
    "            \n",
    "            # Apply filters based on mode\n",
    "            if self.strict_mode:\n",
    "                result['passes_filters'] = (plausibility['plausible'] and \n",
    "                                          len(plausibility['warnings']) == 0)\n",
    "            else:\n",
    "                result['passes_filters'] = plausibility['plausible']\n",
    "        else:\n",
    "            result['chemically_plausible'] = False\n",
    "            result['passes_filters'] = False\n",
    "        \n",
    "        # Update stats\n",
    "        self.validation_stats['total_processed'] += 1\n",
    "        if result['is_valid']:\n",
    "            self.validation_stats['valid_smiles'] += 1\n",
    "        if result.get('chemically_plausible', False):\n",
    "            self.validation_stats['chemically_plausible'] += 1\n",
    "        if result.get('passes_filters', False):\n",
    "            self.validation_stats['passed_filters'] += 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def validate_batch(self, smiles_list: List[str]) -> List[Dict[str, any]]:\n",
    "        \"\"\"Validate a batch of SMILES strings.\"\"\"\n",
    "        return [self.validate_structure(smiles) for smiles in smiles_list]\n",
    "    \n",
    "    def get_filtered_structures(self, smiles_list: List[str]) -> List[str]:\n",
    "        \"\"\"Return only the structures that pass all validation checks.\"\"\"\n",
    "        results = self.validate_batch(smiles_list)\n",
    "        return [r['canonical_smiles'] for r in results \n",
    "                if r['passes_filters'] and r['canonical_smiles']]\n",
    "    \n",
    "    def get_validation_report(self) -> str:\n",
    "        \"\"\"Generate a summary report of validation statistics.\"\"\"\n",
    "        stats = self.validation_stats\n",
    "        total = stats['total_processed']\n",
    "        \n",
    "        if total == 0:\n",
    "            return \"No structures processed yet.\"\n",
    "        \n",
    "        report = f\"\"\"\n",
    "Validation Report:\n",
    "==================\n",
    "Total structures processed: {total}\n",
    "Valid SMILES: {stats['valid_smiles']} ({stats['valid_smiles']/total*100:.1f}%)\n",
    "Chemically plausible: {stats['chemically_plausible']} ({stats['chemically_plausible']/total*100:.1f}%)\n",
    "Passed all filters: {stats['passed_filters']} ({stats['passed_filters']/total*100:.1f}%)\n",
    "\n",
    "Success rate: {stats['passed_filters']/total*100:.1f}%\n",
    "\"\"\"\n",
    "        return report.strip()\n",
    "\n",
    "# Demonstration with simulated LLM output\n",
    "print(\"LLM Chemical Validator Demo\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simulate a mix of good and problematic LLM-generated structures\n",
    "llm_output = [\n",
    "    \"CCO\",  # ethanol - should pass\n",
    "    \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",  # ibuprofen - should pass\n",
    "    \"c1ccccc1\",  # benzene - should pass\n",
    "    \"invalidsmiles\",  # invalid SMILES\n",
    "    \"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\",  # very long chain\n",
    "    \"C1=CC=C(C=C1)C(=O)O\",  # benzoic acid - should pass\n",
    "    \"C[C@H](N)C(=O)O\",  # alanine - should pass\n",
    "    \"C1CCC\",  # invalid - unclosed ring\n",
    "    \"CC(C)(C)(C)(C)C\",  # too many bonds\n",
    "    \"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\",  # extremely long\n",
    "]\n",
    "\n",
    "# Test with normal mode\n",
    "print(\"Testing with Normal Mode:\")\n",
    "validator_normal = LLMChemicalValidator(strict_mode=False)\n",
    "filtered_normal = validator_normal.get_filtered_structures(llm_output)\n",
    "\n",
    "print(f\"Input structures: {len(llm_output)}\")\n",
    "print(f\"Structures passing validation: {len(filtered_normal)}\")\n",
    "print(\"\\nPassed structures:\")\n",
    "for i, smiles in enumerate(filtered_normal, 1):\n",
    "    print(f\"{i}. {smiles}\")\n",
    "\n",
    "print(validator_normal.get_validation_report())\n",
    "\n",
    "# Test with strict mode\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Testing with Strict Mode:\")\n",
    "validator_strict = LLMChemicalValidator(strict_mode=True)\n",
    "filtered_strict = validator_strict.get_filtered_structures(llm_output)\n",
    "\n",
    "print(f\"Structures passing strict validation: {len(filtered_strict)}\")\n",
    "print(validator_strict.get_validation_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ef8d6",
   "metadata": {},
   "source": [
    "# From Molecules to Text: Generating Rich Descriptions for LLM Training\n",
    "\n",
    "While validation is crucial for processing LLM outputs, the reverse direction - converting molecular structures into natural language descriptions - is equally important for training chemical AI systems and creating meaningful prompts. RDKit's rich chemical analysis capabilities make it possible to generate detailed, chemically-informed text descriptions of molecules.\n",
    "\n",
    "This approach is valuable for:\n",
    "- Creating training data for chemistry-focused LLMs\n",
    "- Building chemical chatbots with rich molecular knowledge\n",
    "- Making chemical databases more searchable with natural language\n",
    "- Generating explanatory text for chemical education applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75bff299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molecular Feature Extraction Examples:\n",
      "==================================================\n",
      "\n",
      "Ethanol (CCO):\n",
      "  Formula: C2H6O\n",
      "  MW: 46.07 Da\n",
      "  LogP: -0.0\n",
      "  TPSA: 20.23 Ų\n",
      "  Rings: 0 (aromatic: 0)\n",
      "  H-bond donors/acceptors: 1/1\n",
      "  Functional groups: alcohol(1)\n",
      "  Drug-like: True\n",
      "\n",
      "Ibuprofen (CC(C)CC1=CC=C(C=C1)C(C)C(=O)O):\n",
      "  Formula: C13H18O2\n",
      "  MW: 206.28 Da\n",
      "  LogP: 3.07\n",
      "  TPSA: 37.3 Ų\n",
      "  Rings: 1 (aromatic: 1)\n",
      "  H-bond donors/acceptors: 1/1\n",
      "  Functional groups: carboxylic_acid(1), alcohol(1), aromatic_ring(1)\n",
      "  Drug-like: True\n",
      "\n",
      "Benzoic acid (C1=CC=C(C=C1)C(=O)O):\n",
      "  Formula: C7H6O2\n",
      "  MW: 122.12 Da\n",
      "  LogP: 1.38\n",
      "  TPSA: 37.3 Ų\n",
      "  Rings: 1 (aromatic: 1)\n",
      "  H-bond donors/acceptors: 1/1\n",
      "  Functional groups: carboxylic_acid(1), alcohol(1), aromatic_ring(1)\n",
      "  Drug-like: True\n",
      "\n",
      "Aspirin (CC(=O)OC1=CC=CC=C1C(=O)O):\n",
      "  Formula: C9H8O4\n",
      "  MW: 180.16 Da\n",
      "  LogP: 1.31\n",
      "  TPSA: 63.6 Ų\n",
      "  Rings: 1 (aromatic: 1)\n",
      "  H-bond donors/acceptors: 1/3\n",
      "  Functional groups: carboxylic_acid(1), ester(1), alcohol(1), ether(1), aromatic_ring(1)\n",
      "  Drug-like: True\n",
      "\n",
      "Caffeine (CN1C=NC2=C1C(=O)N(C(=O)N2C)C):\n",
      "  Formula: C8H10N4O2\n",
      "  MW: 194.19 Da\n",
      "  LogP: -1.03\n",
      "  TPSA: 61.82 Ų\n",
      "  Rings: 2 (aromatic: 2)\n",
      "  H-bond donors/acceptors: 0/6\n",
      "  Functional groups: None detected\n",
      "  Drug-like: True\n"
     ]
    }
   ],
   "source": [
    "def extract_molecular_features(mol: Chem.Mol) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Extract comprehensive molecular features suitable for text generation.\n",
    "    This creates a rich feature dictionary that can be converted to natural language.\n",
    "    \"\"\"\n",
    "    if mol is None:\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        # Basic molecular properties\n",
    "        features = {\n",
    "            'smiles': Chem.MolToSmiles(mol),\n",
    "            'molecular_formula': rdMolDescriptors.CalcMolFormula(mol),\n",
    "            'molecular_weight': round(Descriptors.MolWt(mol), 2),\n",
    "            'num_atoms': mol.GetNumAtoms(),\n",
    "            'num_heavy_atoms': mol.GetNumHeavyAtoms(),\n",
    "            'num_bonds': mol.GetNumBonds(),\n",
    "        }\n",
    "        \n",
    "        # Ring and aromaticity information\n",
    "        features.update({\n",
    "            'num_rings': rdMolDescriptors.CalcNumRings(mol),\n",
    "            'num_aromatic_rings': rdMolDescriptors.CalcNumAromaticRings(mol),\n",
    "            'num_saturated_rings': rdMolDescriptors.CalcNumSaturatedRings(mol),\n",
    "            'num_aliphatic_rings': rdMolDescriptors.CalcNumAliphaticRings(mol),\n",
    "        })\n",
    "        \n",
    "        # Physicochemical properties\n",
    "        features.update({\n",
    "            'logp': round(Descriptors.MolLogP(mol), 2),\n",
    "            'tpsa': round(Descriptors.TPSA(mol), 2),\n",
    "            'h_bond_donors': Descriptors.NumHDonors(mol),\n",
    "            'h_bond_acceptors': Descriptors.NumHAcceptors(mol),\n",
    "            'rotatable_bonds': Descriptors.NumRotatableBonds(mol),\n",
    "        })\n",
    "        \n",
    "        # Atom type counts\n",
    "        atom_counts = {}\n",
    "        for atom in mol.GetAtoms():\n",
    "            symbol = atom.GetSymbol()\n",
    "            atom_counts[symbol] = atom_counts.get(symbol, 0) + 1\n",
    "        features['atom_composition'] = atom_counts\n",
    "        \n",
    "        # Functional group analysis (simplified)\n",
    "        functional_groups = []\n",
    "        \n",
    "        # Check for common functional groups using SMARTS\n",
    "        fg_patterns = {\n",
    "            'carboxylic_acid': '[CX3](=O)[OX2H1]',\n",
    "            'ester': '[#6][CX3](=O)[OX2H0][#6]',\n",
    "            'amide': '[CX3](=[OX1])[NX3H2]',\n",
    "            'alcohol': '[OX2H]',\n",
    "            'amine': '[NX3;H2,H1;!$(NC=O)]',\n",
    "            'ketone': '[#6][CX3](=O)[#6]',\n",
    "            'aldehyde': '[CX3H1](=O)[#6]',\n",
    "            'ether': '[OD2]([#6])[#6]',\n",
    "            'phenol': '[OX2H][cX3]:[c]',\n",
    "            'nitro': '[NX3+](=O)[O-]',\n",
    "            'aromatic_ring': 'c1ccccc1',\n",
    "        }\n",
    "        \n",
    "        for fg_name, smarts in fg_patterns.items():\n",
    "            pattern = Chem.MolFromSmarts(smarts)\n",
    "            if pattern and mol.HasSubstructMatch(pattern):\n",
    "                matches = mol.GetSubstructMatches(pattern)\n",
    "                if matches:\n",
    "                    functional_groups.append(f\"{fg_name}({len(matches)})\")\n",
    "        \n",
    "        features['functional_groups'] = functional_groups\n",
    "        \n",
    "        # Drug-likeness assessment\n",
    "        lipinski_violations = []\n",
    "        if features['molecular_weight'] > 500:\n",
    "            lipinski_violations.append('MW > 500')\n",
    "        if features['logp'] > 5:\n",
    "            lipinski_violations.append('LogP > 5')\n",
    "        if features['h_bond_donors'] > 5:\n",
    "            lipinski_violations.append('H-donors > 5')\n",
    "        if features['h_bond_acceptors'] > 10:\n",
    "            lipinski_violations.append('H-acceptors > 10')\n",
    "        \n",
    "        features['lipinski_violations'] = lipinski_violations\n",
    "        features['drug_like'] = len(lipinski_violations) <= 1\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'error': f\"Feature extraction failed: {str(e)}\"}\n",
    "\n",
    "# Test the function with some example molecules\n",
    "test_molecules = [\n",
    "    (\"CCO\", \"Ethanol\"),\n",
    "    (\"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\", \"Ibuprofen\"),\n",
    "    (\"C1=CC=C(C=C1)C(=O)O\", \"Benzoic acid\"),\n",
    "    (\"CC(=O)OC1=CC=CC=C1C(=O)O\", \"Aspirin\"),\n",
    "    (\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\", \"Caffeine\"),\n",
    "]\n",
    "\n",
    "print(\"Molecular Feature Extraction Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for smiles, name in test_molecules:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    features = extract_molecular_features(mol)\n",
    "    \n",
    "    print(f\"\\n{name} ({smiles}):\")\n",
    "    print(f\"  Formula: {features.get('molecular_formula', 'N/A')}\")\n",
    "    print(f\"  MW: {features.get('molecular_weight', 'N/A')} Da\")\n",
    "    print(f\"  LogP: {features.get('logp', 'N/A')}\")\n",
    "    print(f\"  TPSA: {features.get('tpsa', 'N/A')} Ų\")\n",
    "    print(f\"  Rings: {features.get('num_rings', 0)} (aromatic: {features.get('num_aromatic_rings', 0)})\")\n",
    "    print(f\"  H-bond donors/acceptors: {features.get('h_bond_donors', 0)}/{features.get('h_bond_acceptors', 0)}\")\n",
    "    print(f\"  Functional groups: {', '.join(features.get('functional_groups', [])) or 'None detected'}\")\n",
    "    print(f\"  Drug-like: {features.get('drug_like', False)}\")\n",
    "    if features.get('lipinski_violations'):\n",
    "        print(f\"  Lipinski violations: {', '.join(features['lipinski_violations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103d268",
   "metadata": {},
   "source": [
    "## Converting Features to Natural Language\n",
    "\n",
    "Now let's create functions that transform these molecular features into natural language descriptions suitable for LLM training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d004af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Description Examples:\n",
      "============================================================\n",
      "\n",
      "Ibuprofen (CC(C)CC1=CC=C(C=C1)C(C)C(=O)O):\n",
      "------------------------------------------\n",
      "\n",
      "Concise style:\n",
      "This is C13H18O2 with molecular weight 206.28 Da. Contains carboxylic acid, alcohol, aromatic ring functional groups.\n",
      "\n",
      "Technical style:\n",
      "Molecular formula C13H18O2 (MW: 206.28 Da). 1 ring(s) including 1 aromatic ring(s). LogP: 3.07, TPSA: 37.3 Ų. H-bond donors: 1, acceptors: 1. Complies with Lipinski's Rule of Five.\n",
      "\n",
      "Detailed style:\n",
      "This compound has the molecular formula C13H18O2 and a molecular weight of 206.28 daltons. The structure contains 15 heavy atoms, 1 aromatic ring(s). It is composed of 13 C atoms, 2 O atoms. Functional groups present include carboxylic acid, alcohol and aromatic ring. The compound exhibits lipophilic character. This molecule satisfies Lipinski's Rule of Five, suggesting good oral bioavailability potential.\n",
      "\n",
      "Educational style:\n",
      "This molecule, with formula C13H18O2, is an organic compound weighing 206.28 daltons. It contains 1 aromatic ring(s), which are stable ring structures with delocalized electrons that give the molecule special stability and chemical properties. Functional groups are specific arrangements of atoms that give molecules their chemical reactivity. This molecule contains carboxylic acid groups (which can donate protons and are often acidic), alcohol groups (which can form hydrogen bonds). The molecule's size and properties suggest it could potentially be developed as an oral medication.\n",
      "\n",
      "Aspirin (CC(=O)OC1=CC=CC=C1C(=O)O):\n",
      "-----------------------------------\n",
      "\n",
      "Concise style:\n",
      "This is C9H8O4 with molecular weight 180.16 Da. Contains carboxylic acid, ester, alcohol, ether, aromatic ring functional groups.\n",
      "\n",
      "Technical style:\n",
      "Molecular formula C9H8O4 (MW: 180.16 Da). 1 ring(s) including 1 aromatic ring(s). LogP: 1.31, TPSA: 63.6 Ų. H-bond donors: 1, acceptors: 3. Complies with Lipinski's Rule of Five.\n",
      "\n",
      "Detailed style:\n",
      "This compound has the molecular formula C9H8O4 and a molecular weight of 180.16 daltons. The structure contains 13 heavy atoms, 1 aromatic ring(s). It is composed of 9 C atoms, 4 O atoms. Functional groups present include carboxylic acid, ester, alcohol, ether and aromatic ring. The compound exhibits moderate lipophilicity. This molecule satisfies Lipinski's Rule of Five, suggesting good oral bioavailability potential.\n",
      "\n",
      "Educational style:\n",
      "This molecule, with formula C9H8O4, is an organic compound weighing 180.16 daltons. It contains 1 aromatic ring(s), which are stable ring structures with delocalized electrons that give the molecule special stability and chemical properties. Functional groups are specific arrangements of atoms that give molecules their chemical reactivity. This molecule contains carboxylic acid groups (which can donate protons and are often acidic), ester groups (often found in fats and can be hydrolyzed), alcohol groups (which can form hydrogen bonds), ether groups (which are generally unreactive). The molecule's size and properties suggest it could potentially be developed as an oral medication.\n",
      "\n",
      "Caffeine (CN1C=NC2=C1C(=O)N(C(=O)N2C)C):\n",
      "----------------------------------------\n",
      "\n",
      "Concise style:\n",
      "This is C8H10N4O2 with molecular weight 194.19 Da.\n",
      "\n",
      "Technical style:\n",
      "Molecular formula C8H10N4O2 (MW: 194.19 Da). 2 ring(s) including 2 aromatic ring(s). LogP: -1.03, TPSA: 61.82 Ų. H-bond donors: 0, acceptors: 6. Complies with Lipinski's Rule of Five.\n",
      "\n",
      "Detailed style:\n",
      "This compound has the molecular formula C8H10N4O2 and a molecular weight of 194.19 daltons. The structure contains 14 heavy atoms, 2 aromatic ring(s). It is composed of 8 C atoms, 4 N atoms, 2 O atoms. The compound exhibits hydrophilic nature. This molecule satisfies Lipinski's Rule of Five, suggesting good oral bioavailability potential.\n",
      "\n",
      "Educational style:\n",
      "This molecule, with formula C8H10N4O2, is an organic compound weighing 194.19 daltons. It contains 2 aromatic ring(s), which are stable ring structures with delocalized electrons that give the molecule special stability and chemical properties. The molecule's size and properties suggest it could potentially be developed as an oral medication.\n"
     ]
    }
   ],
   "source": [
    "def generate_molecular_description(mol: Chem.Mol, style: str = 'detailed') -> str:\n",
    "    \"\"\"\n",
    "    Generate natural language descriptions of molecules in different styles.\n",
    "    \n",
    "    Args:\n",
    "        mol: RDKit molecule object\n",
    "        style: 'detailed', 'concise', 'technical', or 'educational'\n",
    "    \n",
    "    Returns:\n",
    "        Natural language description of the molecule\n",
    "    \"\"\"\n",
    "    if mol is None:\n",
    "        return \"Invalid molecule structure.\"\n",
    "    \n",
    "    features = extract_molecular_features(mol)\n",
    "    if 'error' in features:\n",
    "        return f\"Could not analyze molecule: {features['error']}\"\n",
    "    \n",
    "    if style == 'concise':\n",
    "        return _generate_concise_description(features)\n",
    "    elif style == 'technical':\n",
    "        return _generate_technical_description(features)\n",
    "    elif style == 'educational':\n",
    "        return _generate_educational_description(features)\n",
    "    else:  # detailed\n",
    "        return _generate_detailed_description(features)\n",
    "\n",
    "def _generate_concise_description(features: Dict) -> str:\n",
    "    \"\"\"Generate a brief, factual description.\"\"\"\n",
    "    desc = f\"This is {features['molecular_formula']} with molecular weight {features['molecular_weight']} Da.\"\n",
    "    \n",
    "    if features['functional_groups']:\n",
    "        fg_text = ', '.join([fg.split('(')[0].replace('_', ' ') for fg in features['functional_groups']])\n",
    "        desc += f\" Contains {fg_text} functional groups.\"\n",
    "    \n",
    "    return desc\n",
    "\n",
    "def _generate_technical_description(features: Dict) -> str:\n",
    "    \"\"\"Generate a technical description with precise chemical language.\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Basic structure\n",
    "    parts.append(f\"Molecular formula {features['molecular_formula']} (MW: {features['molecular_weight']} Da)\")\n",
    "    \n",
    "    # Ring systems\n",
    "    if features['num_rings'] > 0:\n",
    "        ring_desc = f\"{features['num_rings']} ring(s)\"\n",
    "        if features['num_aromatic_rings'] > 0:\n",
    "            ring_desc += f\" including {features['num_aromatic_rings']} aromatic ring(s)\"\n",
    "        parts.append(ring_desc)\n",
    "    \n",
    "    # Physicochemical properties\n",
    "    parts.append(f\"LogP: {features['logp']}, TPSA: {features['tpsa']} Ų\")\n",
    "    \n",
    "    # Hydrogen bonding\n",
    "    if features['h_bond_donors'] > 0 or features['h_bond_acceptors'] > 0:\n",
    "        parts.append(f\"H-bond donors: {features['h_bond_donors']}, acceptors: {features['h_bond_acceptors']}\")\n",
    "    \n",
    "    # Drug-likeness\n",
    "    if features['drug_like']:\n",
    "        parts.append(\"Complies with Lipinski's Rule of Five\")\n",
    "    elif features['lipinski_violations']:\n",
    "        parts.append(f\"Violates Lipinski's Rule: {', '.join(features['lipinski_violations'])}\")\n",
    "    \n",
    "    return \". \".join(parts) + \".\"\n",
    "\n",
    "def _generate_detailed_description(features: Dict) -> str:\n",
    "    \"\"\"Generate a comprehensive description suitable for training data.\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Introduction\n",
    "    parts.append(f\"This compound has the molecular formula {features['molecular_formula']} and a molecular weight of {features['molecular_weight']} daltons.\")\n",
    "    \n",
    "    # Structural features\n",
    "    structure_parts = []\n",
    "    if features['num_heavy_atoms'] > 0:\n",
    "        structure_parts.append(f\"{features['num_heavy_atoms']} heavy atoms\")\n",
    "    \n",
    "    if features['num_rings'] > 0:\n",
    "        if features['num_aromatic_rings'] > 0 and features['num_saturated_rings'] > 0:\n",
    "            structure_parts.append(f\"{features['num_rings']} rings ({features['num_aromatic_rings']} aromatic, {features['num_saturated_rings']} saturated)\")\n",
    "        elif features['num_aromatic_rings'] > 0:\n",
    "            structure_parts.append(f\"{features['num_aromatic_rings']} aromatic ring(s)\")\n",
    "        else:\n",
    "            structure_parts.append(f\"{features['num_rings']} saturated ring(s)\")\n",
    "    \n",
    "    if structure_parts:\n",
    "        parts.append(f\"The structure contains {', '.join(structure_parts)}.\")\n",
    "    \n",
    "    # Atom composition\n",
    "    atoms = features['atom_composition']\n",
    "    if len(atoms) > 1:\n",
    "        atom_desc = []\n",
    "        for atom, count in sorted(atoms.items()):\n",
    "            if atom != 'H':  # Skip hydrogen for brevity\n",
    "                if count == 1:\n",
    "                    atom_desc.append(f\"one {atom}\")\n",
    "                else:\n",
    "                    atom_desc.append(f\"{count} {atom} atoms\")\n",
    "        if atom_desc:\n",
    "            parts.append(f\"It is composed of {', '.join(atom_desc)}.\")\n",
    "    \n",
    "    # Functional groups\n",
    "    if features['functional_groups']:\n",
    "        fg_names = [fg.split('(')[0].replace('_', ' ') for fg in features['functional_groups']]\n",
    "        if len(fg_names) == 1:\n",
    "            parts.append(f\"The molecule contains a {fg_names[0]} functional group.\")\n",
    "        else:\n",
    "            parts.append(f\"Functional groups present include {', '.join(fg_names[:-1])} and {fg_names[-1]}.\")\n",
    "    \n",
    "    # Physicochemical properties\n",
    "    prop_desc = []\n",
    "    if features['logp'] is not None:\n",
    "        if features['logp'] > 3:\n",
    "            prop_desc.append(\"lipophilic character\")\n",
    "        elif features['logp'] < 0:\n",
    "            prop_desc.append(\"hydrophilic nature\")\n",
    "        else:\n",
    "            prop_desc.append(\"moderate lipophilicity\")\n",
    "    \n",
    "    if features['tpsa'] > 90:\n",
    "        prop_desc.append(\"high polar surface area\")\n",
    "    elif features['tpsa'] < 30:\n",
    "        prop_desc.append(\"low polar surface area\")\n",
    "    \n",
    "    if prop_desc:\n",
    "        parts.append(f\"The compound exhibits {' and '.join(prop_desc)}.\")\n",
    "    \n",
    "    # Drug-likeness assessment\n",
    "    if features['drug_like']:\n",
    "        parts.append(\"This molecule satisfies Lipinski's Rule of Five, suggesting good oral bioavailability potential.\")\n",
    "    elif features['lipinski_violations']:\n",
    "        parts.append(f\"The compound violates Lipinski's Rule of Five due to {', '.join(features['lipinski_violations'])}, which may affect its drug-like properties.\")\n",
    "    \n",
    "    return \" \".join(parts)\n",
    "\n",
    "def _generate_educational_description(features: Dict) -> str:\n",
    "    \"\"\"Generate an educational description explaining chemical concepts.\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Start with basics\n",
    "    parts.append(f\"This molecule, with formula {features['molecular_formula']}, is an organic compound weighing {features['molecular_weight']} daltons.\")\n",
    "    \n",
    "    # Explain ring systems in educational terms\n",
    "    if features['num_aromatic_rings'] > 0:\n",
    "        parts.append(f\"It contains {features['num_aromatic_rings']} aromatic ring(s), which are stable ring structures with delocalized electrons that give the molecule special stability and chemical properties.\")\n",
    "    elif features['num_rings'] > 0:\n",
    "        parts.append(f\"The molecule has {features['num_rings']} ring structure(s), which can affect its shape and biological activity.\")\n",
    "    \n",
    "    # Explain functional groups\n",
    "    if features['functional_groups']:\n",
    "        parts.append(\"Functional groups are specific arrangements of atoms that give molecules their chemical reactivity.\")\n",
    "        fg_explanations = {\n",
    "            'carboxylic_acid': \"carboxylic acid groups (which can donate protons and are often acidic)\",\n",
    "            'alcohol': \"alcohol groups (which can form hydrogen bonds)\",\n",
    "            'amine': \"amine groups (which are basic and can accept protons)\",\n",
    "            'ketone': \"ketone groups (which are reactive carbonyl groups)\",\n",
    "            'ester': \"ester groups (often found in fats and can be hydrolyzed)\",\n",
    "            'ether': \"ether groups (which are generally unreactive)\"\n",
    "        }\n",
    "        \n",
    "        explained_groups = []\n",
    "        for fg in features['functional_groups']:\n",
    "            fg_name = fg.split('(')[0]\n",
    "            if fg_name in fg_explanations:\n",
    "                explained_groups.append(fg_explanations[fg_name])\n",
    "        \n",
    "        if explained_groups:\n",
    "            parts.append(f\"This molecule contains {', '.join(explained_groups)}.\")\n",
    "    \n",
    "    # Explain drug-likeness in simple terms\n",
    "    if features['drug_like']:\n",
    "        parts.append(\"The molecule's size and properties suggest it could potentially be developed as an oral medication.\")\n",
    "    elif features['lipinski_violations']:\n",
    "        parts.append(\"The molecule is quite large or has properties that might make it challenging to develop as an oral drug.\")\n",
    "    \n",
    "    return \" \".join(parts)\n",
    "\n",
    "# Test the different description styles\n",
    "test_molecules = [\n",
    "    (\"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\", \"Ibuprofen\"),\n",
    "    (\"CC(=O)OC1=CC=CC=C1C(=O)O\", \"Aspirin\"),\n",
    "    (\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\", \"Caffeine\"),\n",
    "]\n",
    "\n",
    "styles = ['concise', 'technical', 'detailed', 'educational']\n",
    "\n",
    "print(\"Natural Language Description Examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for smiles, name in test_molecules:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    print(f\"\\n{name} ({smiles}):\")\n",
    "    print(\"-\" * (len(name) + len(smiles) + 4))\n",
    "    \n",
    "    for style in styles:\n",
    "        description = generate_molecular_description(mol, style)\n",
    "        print(f\"\\n{style.title()} style:\")\n",
    "        print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d594bb7",
   "metadata": {},
   "source": [
    "## Creating Structured Training Data\n",
    "\n",
    "For training LLMs, you often need structured datasets that pair chemical structures with their descriptions. Here's how to create such datasets systematically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7546d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Molecule-Text Dataset...\n",
      "Generated 15 training examples\n",
      "\n",
      "Example training entries:\n",
      "==================================================\n",
      "\n",
      "Example 1:\n",
      "Task: molecule_description\n",
      "Molecule: Ethanol\n",
      "Prompt: Describe the chemical structure CCO:\n",
      "Response: This compound has the molecular formula C2H6O and a molecular weight of 46.07 daltons. The structure...\n",
      "\n",
      "Example 2:\n",
      "Task: chemical_qa\n",
      "Molecule: Ethanol\n",
      "Prompt: What can you tell me about the molecule with SMILES CCO?\n",
      "Response: This compound has the molecular formula C2H6O and a molecular weight of 46.07 daltons. The structure...\n",
      "\n",
      "Example 3:\n",
      "Task: named_molecule_description\n",
      "Molecule: Ethanol\n",
      "Prompt: Describe the chemical structure and properties of Ethanol:\n",
      "Response: Ethanol (CCO) is a compound where this compound has the molecular formula c2h6o and a molecular weig...\n",
      "\n",
      "==================================================\n",
      "Creating Property Prediction Dataset...\n",
      "Generated 15 property prediction examples\n",
      "\n",
      "Example property prediction entries:\n",
      "\n",
      "Example 1:\n",
      "Property: molecular_weight\n",
      "Molecule: CCO\n",
      "Prompt: What is the molecular weight of CCO?\n",
      "Response: The molecular weight of CCO is 46.07. The molecular weight is 46.07 daltons, which indicates a relatively small molecule.\n",
      "\n",
      "Example 2:\n",
      "Property: logp\n",
      "Molecule: CCO\n",
      "Prompt: What is the logp of CCO?\n",
      "Response: The logp of CCO is -0.0. The LogP value is -0.0, indicating balanced lipophilicity suitable for oral drugs.\n",
      "\n",
      "Example 3:\n",
      "Property: h_bond_donors\n",
      "Molecule: CCO\n",
      "Prompt: What is the h bond donors of CCO?\n",
      "Response: The h bond donors of CCO is 1. This molecule has 1 hydrogen bond donor(s), which is within the acceptable range for drug-like molecules.\n"
     ]
    }
   ],
   "source": [
    "def create_molecule_text_dataset(smiles_list: List[str], \n",
    "                                names: Optional[List[str]] = None,\n",
    "                                include_multiple_styles: bool = True) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Create a structured dataset pairing molecules with text descriptions.\n",
    "    Suitable for fine-tuning LLMs on chemical tasks.\n",
    "    \n",
    "    Args:\n",
    "        smiles_list: List of SMILES strings\n",
    "        names: Optional list of molecule names\n",
    "        include_multiple_styles: Whether to generate multiple description styles\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with 'structure', 'description', and metadata\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue  # Skip invalid molecules\n",
    "        \n",
    "        name = names[i] if names and i < len(names) else f\"Compound_{i+1}\"\n",
    "        canonical_smiles = Chem.MolToSmiles(mol)\n",
    "        \n",
    "        if include_multiple_styles:\n",
    "            styles = ['concise', 'technical', 'detailed', 'educational']\n",
    "        else:\n",
    "            styles = ['detailed']\n",
    "        \n",
    "        for style in styles:\n",
    "            description = generate_molecular_description(mol, style)\n",
    "            \n",
    "            # Create training example in various formats\n",
    "            \n",
    "            # Format 1: Direct description\n",
    "            dataset.append({\n",
    "                'task_type': 'molecule_description',\n",
    "                'style': style,\n",
    "                'input_smiles': smiles,\n",
    "                'canonical_smiles': canonical_smiles,\n",
    "                'molecule_name': name,\n",
    "                'description': description,\n",
    "                'prompt': f\"Describe the chemical structure {canonical_smiles}:\",\n",
    "                'response': description\n",
    "            })\n",
    "            \n",
    "            # Format 2: Question-answer format\n",
    "            dataset.append({\n",
    "                'task_type': 'chemical_qa',\n",
    "                'style': style,\n",
    "                'input_smiles': smiles,\n",
    "                'canonical_smiles': canonical_smiles,\n",
    "                'molecule_name': name,\n",
    "                'description': description,\n",
    "                'prompt': f\"What can you tell me about the molecule with SMILES {canonical_smiles}?\",\n",
    "                'response': description\n",
    "            })\n",
    "            \n",
    "            # Format 3: Named molecule description\n",
    "            if name != f\"Compound_{i+1}\":\n",
    "                dataset.append({\n",
    "                    'task_type': 'named_molecule_description',\n",
    "                    'style': style,\n",
    "                    'input_smiles': smiles,\n",
    "                    'canonical_smiles': canonical_smiles,\n",
    "                    'molecule_name': name,\n",
    "                    'description': description,\n",
    "                    'prompt': f\"Describe the chemical structure and properties of {name}:\",\n",
    "                    'response': f\"{name} ({canonical_smiles}) is a compound where {description.lower()}\"\n",
    "                })\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def create_property_prediction_dataset(smiles_list: List[str], \n",
    "                                     target_properties: List[str] = None) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Create a dataset for training property prediction with natural language explanations.\n",
    "    \"\"\"\n",
    "    if target_properties is None:\n",
    "        target_properties = ['molecular_weight', 'logp', 'h_bond_donors', 'h_bond_acceptors', 'drug_like']\n",
    "    \n",
    "    dataset = []\n",
    "    \n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "        \n",
    "        features = extract_molecular_features(mol)\n",
    "        canonical_smiles = Chem.MolToSmiles(mol)\n",
    "        \n",
    "        for prop in target_properties:\n",
    "            if prop in features:\n",
    "                value = features[prop]\n",
    "                \n",
    "                # Create natural language explanations for properties\n",
    "                if prop == 'molecular_weight':\n",
    "                    explanation = f\"The molecular weight is {value} daltons, which \"\n",
    "                    if value < 200:\n",
    "                        explanation += \"indicates a relatively small molecule.\"\n",
    "                    elif value > 500:\n",
    "                        explanation += \"suggests a large molecule that may have bioavailability issues.\"\n",
    "                    else:\n",
    "                        explanation += \"is in a reasonable range for drug-like compounds.\"\n",
    "                        \n",
    "                elif prop == 'logp':\n",
    "                    explanation = f\"The LogP value is {value}, indicating \"\n",
    "                    if value > 3:\n",
    "                        explanation += \"high lipophilicity and potential membrane permeability.\"\n",
    "                    elif value < 0:\n",
    "                        explanation += \"hydrophilic character and good water solubility.\"\n",
    "                    else:\n",
    "                        explanation += \"balanced lipophilicity suitable for oral drugs.\"\n",
    "                        \n",
    "                elif prop == 'h_bond_donors':\n",
    "                    explanation = f\"This molecule has {value} hydrogen bond donor(s), which \"\n",
    "                    if value == 0:\n",
    "                        explanation += \"means it cannot donate hydrogen bonds.\"\n",
    "                    elif value <= 5:\n",
    "                        explanation += \"is within the acceptable range for drug-like molecules.\"\n",
    "                    else:\n",
    "                        explanation += \"may limit its ability to cross biological membranes.\"\n",
    "                        \n",
    "                elif prop == 'drug_like':\n",
    "                    explanation = f\"This molecule {'is' if value else 'is not'} drug-like according to Lipinski's Rule of Five.\"\n",
    "                    \n",
    "                else:\n",
    "                    explanation = f\"The {prop.replace('_', ' ')} value is {value}.\"\n",
    "                \n",
    "                dataset.append({\n",
    "                    'task_type': 'property_prediction',\n",
    "                    'property': prop,\n",
    "                    'input_smiles': smiles,\n",
    "                    'canonical_smiles': canonical_smiles,\n",
    "                    'property_value': value,\n",
    "                    'prompt': f\"What is the {prop.replace('_', ' ')} of {canonical_smiles}?\",\n",
    "                    'response': f\"{value}\",\n",
    "                    'explanation': explanation,\n",
    "                    'detailed_response': f\"The {prop.replace('_', ' ')} of {canonical_smiles} is {value}. {explanation}\"\n",
    "                })\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Example: Create training datasets\n",
    "example_molecules = [\n",
    "    (\"CCO\", \"Ethanol\"),\n",
    "    (\"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\", \"Ibuprofen\"),\n",
    "    (\"CC(=O)OC1=CC=CC=C1C(=O)O\", \"Aspirin\"),\n",
    "    (\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\", \"Caffeine\"),\n",
    "    (\"CC1=CC=C(C=C1)C(C)C(=O)O\", \"2-(4-methylphenyl)propanoic acid\"),\n",
    "]\n",
    "\n",
    "smiles_only = [mol[0] for mol in example_molecules]\n",
    "names_only = [mol[1] for mol in example_molecules]\n",
    "\n",
    "print(\"Creating Molecule-Text Dataset...\")\n",
    "mol_text_data = create_molecule_text_dataset(smiles_only, names_only, include_multiple_styles=False)\n",
    "\n",
    "print(f\"Generated {len(mol_text_data)} training examples\")\n",
    "print(\"\\nExample training entries:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show a few examples\n",
    "for i, entry in enumerate(mol_text_data[:3]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Task: {entry['task_type']}\")\n",
    "    print(f\"Molecule: {entry['molecule_name']}\")\n",
    "    print(f\"Prompt: {entry['prompt']}\")\n",
    "    print(f\"Response: {entry['response'][:100]}{'...' if len(entry['response']) > 100 else ''}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating Property Prediction Dataset...\")\n",
    "prop_data = create_property_prediction_dataset(smiles_only[:3])\n",
    "\n",
    "print(f\"Generated {len(prop_data)} property prediction examples\")\n",
    "print(\"\\nExample property prediction entries:\")\n",
    "\n",
    "for i, entry in enumerate(prop_data[:3]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Property: {entry['property']}\")\n",
    "    print(f\"Molecule: {entry['canonical_smiles']}\")\n",
    "    print(f\"Prompt: {entry['prompt']}\")\n",
    "    print(f\"Response: {entry['detailed_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85db2f",
   "metadata": {},
   "source": [
    "## Exporting Data for Different LLM Platforms\n",
    "\n",
    "Different LLM training platforms expect different data formats. Here are functions to export your chemical training data in common formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dfb0c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting Training Data in Different Formats:\n",
      "==================================================\n",
      "Exported 5 entries to demo_huggingface.jsonl (HuggingFace format)\n",
      "Exported 5 entries to demo_openai.jsonl (OpenAI format)\n",
      "Exported 5 entries to demo_llama.json (LLaMA/Alpaca format)\n",
      "\n",
      "Creating Conversational Dataset:\n",
      "Generated 2 conversations\n",
      "\n",
      "Example conversation:\n",
      "==============================\n",
      "Turn 1:\n",
      "User: Can you analyze the structure CCO?\n",
      "Assistant: This compound has the molecular formula C2H6O and a molecular weight of 46.07 daltons. The structure...\n",
      "\n",
      "Turn 2:\n",
      "User: What's its molecular weight?\n",
      "Assistant: The molecular weight is 46.07 daltons.\n",
      "\n",
      "Turn 3:\n",
      "User: Would this be a good drug candidate?\n",
      "Assistant: Yes, this molecule complies with Lipinski's Rule of Five.  The molecule's size and properties sugges...\n",
      "\n",
      "Sample exported data:\n",
      "------------------------------\n",
      "Entry 1: {\"instruction\": \"Describe the chemical structure CCO:\", \"input\": \"CCO\", \"output\": \"This compound has...\n",
      "Entry 2: {\"instruction\": \"What can you tell me about the molecule with SMILES CCO?\", \"input\": \"CCO\", \"output\"...\n"
     ]
    }
   ],
   "source": [
    "def export_for_huggingface(dataset: List[Dict], output_file: str = \"chemical_training_data.jsonl\"):\n",
    "    \"\"\"\n",
    "    Export dataset in HuggingFace datasets format (JSONL).\n",
    "    Each line is a JSON object with 'text' field for language modeling\n",
    "    or 'input'/'output' fields for instruction tuning.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for entry in dataset:\n",
    "            # Format for instruction tuning\n",
    "            hf_entry = {\n",
    "                'instruction': entry['prompt'],\n",
    "                'input': entry.get('canonical_smiles', ''),\n",
    "                'output': entry['response'],\n",
    "                'metadata': {\n",
    "                    'task_type': entry.get('task_type', ''),\n",
    "                    'molecule_name': entry.get('molecule_name', ''),\n",
    "                    'style': entry.get('style', '')\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(hf_entry) + '\\n')\n",
    "    \n",
    "    print(f\"Exported {len(dataset)} entries to {output_file} (HuggingFace format)\")\n",
    "\n",
    "def export_for_openai(dataset: List[Dict], output_file: str = \"chemical_training_data_openai.jsonl\"):\n",
    "    \"\"\"\n",
    "    Export dataset in OpenAI fine-tuning format.\n",
    "    Each line has 'messages' with system/user/assistant format.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for entry in dataset:\n",
    "            openai_entry = {\n",
    "                'messages': [\n",
    "                    {\n",
    "                        'role': 'system',\n",
    "                        'content': 'You are a helpful chemistry assistant that can analyze and describe chemical structures.'\n",
    "                    },\n",
    "                    {\n",
    "                        'role': 'user', \n",
    "                        'content': entry['prompt']\n",
    "                    },\n",
    "                    {\n",
    "                        'role': 'assistant',\n",
    "                        'content': entry['response']\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            f.write(json.dumps(openai_entry) + '\\n')\n",
    "    \n",
    "    print(f\"Exported {len(dataset)} entries to {output_file} (OpenAI format)\")\n",
    "\n",
    "def export_for_llama(dataset: List[Dict], output_file: str = \"chemical_training_data_llama.json\"):\n",
    "    \"\"\"\n",
    "    Export dataset in LLaMA/Alpaca instruction format.\n",
    "    \"\"\"\n",
    "    llama_data = []\n",
    "    \n",
    "    for entry in dataset:\n",
    "        llama_entry = {\n",
    "            'instruction': entry['prompt'],\n",
    "            'input': entry.get('canonical_smiles', ''),\n",
    "            'output': entry['response']\n",
    "        }\n",
    "        llama_data.append(llama_entry)\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(llama_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Exported {len(dataset)} entries to {output_file} (LLaMA/Alpaca format)\")\n",
    "\n",
    "def create_conversational_dataset(smiles_list: List[str], names: List[str] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Create a conversational dataset simulating a chemistry chatbot interaction.\n",
    "    \"\"\"\n",
    "    conversations = []\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "        \n",
    "        name = names[i] if names and i < len(names) else f\"Compound_{i+1}\"\n",
    "        features = extract_molecular_features(mol)\n",
    "        \n",
    "        # Create a multi-turn conversation\n",
    "        conversation = {\n",
    "            'conversation_id': f\"chem_chat_{i+1}\",\n",
    "            'molecule_smiles': smiles,\n",
    "            'molecule_name': name,\n",
    "            'turns': []\n",
    "        }\n",
    "        \n",
    "        # Turn 1: Initial structure inquiry\n",
    "        conversation['turns'].append({\n",
    "            'user': f\"Can you analyze the structure {smiles}?\",\n",
    "            'assistant': generate_molecular_description(mol, 'detailed')\n",
    "        })\n",
    "        \n",
    "        # Turn 2: Property question\n",
    "        if features.get('molecular_weight'):\n",
    "            conversation['turns'].append({\n",
    "                'user': \"What's its molecular weight?\",\n",
    "                'assistant': f\"The molecular weight is {features['molecular_weight']} daltons.\"\n",
    "            })\n",
    "        \n",
    "        # Turn 3: Drug-likeness question\n",
    "        conversation['turns'].append({\n",
    "            'user': \"Would this be a good drug candidate?\",\n",
    "            'assistant': f\"{'Yes' if features.get('drug_like') else 'It may face challenges'}, this molecule {'complies with' if features.get('drug_like') else 'violates'} Lipinski's Rule of Five. {generate_molecular_description(mol, 'educational').split('.')[-2]}.\"\n",
    "        })\n",
    "        \n",
    "        conversations.append(conversation)\n",
    "    \n",
    "    return conversations\n",
    "\n",
    "# Demonstrate the export functions\n",
    "print(\"Exporting Training Data in Different Formats:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use the previously created dataset\n",
    "sample_dataset = mol_text_data[:5]  # Use a small sample for demonstration\n",
    "\n",
    "# Export in different formats\n",
    "export_for_huggingface(sample_dataset, \"demo_huggingface.jsonl\")\n",
    "export_for_openai(sample_dataset, \"demo_openai.jsonl\") \n",
    "export_for_llama(sample_dataset, \"demo_llama.json\")\n",
    "\n",
    "# Create and show conversational dataset\n",
    "print(\"\\nCreating Conversational Dataset:\")\n",
    "conv_data = create_conversational_dataset(smiles_only[:2], names_only[:2])\n",
    "\n",
    "print(f\"Generated {len(conv_data)} conversations\")\n",
    "print(\"\\nExample conversation:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "for i, turn in enumerate(conv_data[0]['turns']):\n",
    "    print(f\"Turn {i+1}:\")\n",
    "    print(f\"User: {turn['user']}\")\n",
    "    print(f\"Assistant: {turn['assistant'][:100]}{'...' if len(turn['assistant']) > 100 else ''}\")\n",
    "    print()\n",
    "\n",
    "# Show file contents (first few lines)\n",
    "print(\"Sample exported data:\")\n",
    "print(\"-\" * 30)\n",
    "try:\n",
    "    with open(\"demo_huggingface.jsonl\", 'r') as f:\n",
    "        lines = f.readlines()[:2]\n",
    "        for i, line in enumerate(lines):\n",
    "            print(f\"Entry {i+1}: {line[:100]}...\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Demo files not created (running in demo mode)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dc602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e3c46d",
   "metadata": {},
   "source": [
    "# Real-World Challenges and Solutions\n",
    "\n",
    "While the integration of RDKit and LLMs offers exciting possibilities, real-world implementations face several challenges. This section addresses common issues and provides practical solutions based on experience with production systems.\n",
    "\n",
    "## Challenge 1: Performance and Scalability\n",
    "\n",
    "When processing large datasets or building real-time applications, performance becomes critical. Let's explore strategies for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ba7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Benchmark:\n",
      "========================================\n",
      "Sequential processing: 0.32 seconds\n",
      "Parallel processing: 0.09 seconds\n",
      "Cached processing: 0.02 seconds\n",
      "Speedup (parallel): 3.7x\n",
      "Speedup (cached): 13.3x\n",
      "\n",
      "Results consistency check:\n",
      "Sequential results: 1000 molecules processed\n",
      "Parallel results: 1000 molecules processed\n",
      "Cached results: 1000 molecules processed\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import time\n",
    "from functools import lru_cache\n",
    "\n",
    "class OptimizedChemicalProcessor:\n",
    "    \"\"\"\n",
    "    An optimized processor for handling large-scale chemical data processing\n",
    "    with RDKit and LLM integration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = None, use_caching: bool = True):\n",
    "        self.max_workers = max_workers or mp.cpu_count()\n",
    "        self.use_caching = use_caching\n",
    "        \n",
    "        # Pre-compile common SMARTS patterns for efficiency\n",
    "        self.functional_group_patterns = {\n",
    "            name: Chem.MolFromSmarts(smarts) for name, smarts in {\n",
    "                'carboxylic_acid': '[CX3](=O)[OX2H1]',\n",
    "                'ester': '[#6][CX3](=O)[OX2H0][#6]',\n",
    "                'alcohol': '[OX2H]',\n",
    "                'amine': '[NX3;H2,H1;!$(NC=O)]',\n",
    "                'ketone': '[#6][CX3](=O)[#6]',\n",
    "                'aromatic_ring': 'c1ccccc1',\n",
    "            }.items()\n",
    "        }\n",
    "    \n",
    "    @lru_cache(maxsize=10000)\n",
    "    def cached_mol_from_smiles(self, smiles: str):\n",
    "        \"\"\"Cached molecule parsing to avoid repeated work.\"\"\"\n",
    "        return Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    def process_smiles_batch_parallel(self, smiles_list: List[str]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Process a batch of SMILES in parallel for better performance.\n",
    "        \"\"\"\n",
    "        # Use ProcessPoolExecutor for CPU-bound tasks\n",
    "        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # Split into chunks to reduce overhead\n",
    "            chunk_size = max(1, len(smiles_list) // (self.max_workers * 4))\n",
    "            chunks = [smiles_list[i:i + chunk_size] \n",
    "                     for i in range(0, len(smiles_list), chunk_size)]\n",
    "            \n",
    "            # Process chunks in parallel\n",
    "            futures = [executor.submit(self._process_chunk, chunk) for chunk in chunks]\n",
    "            results = []\n",
    "            for future in futures:\n",
    "                results.extend(future.result())\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _process_chunk(self, smiles_chunk: List[str]) -> List[Dict]:\n",
    "        \"\"\"Process a chunk of SMILES strings.\"\"\"\n",
    "        results = []\n",
    "        for smiles in smiles_chunk:\n",
    "            try:\n",
    "                if self.use_caching:\n",
    "                    mol = self.cached_mol_from_smiles(smiles)\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                \n",
    "                if mol:\n",
    "                    features = self._extract_features_optimized(mol)\n",
    "                    features['smiles'] = smiles\n",
    "                    results.append(features)\n",
    "                else:\n",
    "                    results.append({'smiles': smiles, 'error': 'Invalid SMILES'})\n",
    "            except Exception as e:\n",
    "                results.append({'smiles': smiles, 'error': str(e)})\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _extract_features_optimized(self, mol: Chem.Mol) -> Dict:\n",
    "        \"\"\"Optimized feature extraction focusing on essential properties.\"\"\"\n",
    "        # Only calculate the most important features to save time\n",
    "        try:\n",
    "            features = {\n",
    "                'molecular_weight': round(Descriptors.MolWt(mol), 2),\n",
    "                'logp': round(Descriptors.MolLogP(mol), 2),\n",
    "                'num_atoms': mol.GetNumAtoms(),\n",
    "                'num_rings': rdMolDescriptors.CalcNumRings(mol),\n",
    "                'h_bond_donors': Descriptors.NumHDonors(mol),\n",
    "                'h_bond_acceptors': Descriptors.NumHAcceptors(mol),\n",
    "            }\n",
    "            \n",
    "            # Fast functional group detection using pre-compiled patterns\n",
    "            functional_groups = []\n",
    "            for fg_name, pattern in self.functional_group_patterns.items():\n",
    "                if mol.HasSubstructMatch(pattern):\n",
    "                    functional_groups.append(fg_name)\n",
    "            \n",
    "            features['functional_groups'] = functional_groups\n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': f'Feature extraction failed: {str(e)}'}\n",
    "\n",
    "# Performance comparison demonstration\n",
    "def benchmark_processing_methods():\n",
    "    \"\"\"Compare different processing approaches for performance.\"\"\"\n",
    "    \n",
    "    # Generate test data\n",
    "    test_smiles = [\n",
    "        \"CCO\", \"c1ccccc1\", \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",\n",
    "        \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\", \"CC(=O)OC1=CC=CC=C1C(=O)O\"\n",
    "    ] * 200  # 1000 molecules for testing\n",
    "    \n",
    "    processor = OptimizedChemicalProcessor()\n",
    "    \n",
    "    print(\"Performance Benchmark:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Method 1: Sequential processing\n",
    "    start_time = time.time()\n",
    "    sequential_results = []\n",
    "    for smiles in test_smiles:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            features = extract_molecular_features(mol)\n",
    "            sequential_results.append(features)\n",
    "    sequential_time = time.time() - start_time\n",
    "    \n",
    "    # Method 2: Parallel processing\n",
    "    start_time = time.time()\n",
    "    parallel_results = processor.process_smiles_batch_parallel(test_smiles)\n",
    "    parallel_time = time.time() - start_time\n",
    "    \n",
    "    # Method 3: Cached processing\n",
    "    start_time = time.time()\n",
    "    cached_results = []\n",
    "    for smiles in test_smiles:\n",
    "        mol = processor.cached_mol_from_smiles(smiles)\n",
    "        if mol:\n",
    "            features = processor._extract_features_optimized(mol)\n",
    "            cached_results.append(features)\n",
    "    cached_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Sequential processing: {sequential_time:.2f} seconds\")\n",
    "    print(f\"Parallel processing: {parallel_time:.2f} seconds\")\n",
    "    print(f\"Cached processing: {cached_time:.2f} seconds\")\n",
    "    print(f\"Speedup (parallel): {sequential_time/parallel_time:.1f}x\")\n",
    "    print(f\"Speedup (cached): {sequential_time/cached_time:.1f}x\")\n",
    "    \n",
    "    # Verify results are consistent\n",
    "    print(f\"\\nResults consistency check:\")\n",
    "    print(f\"Sequential results: {len(sequential_results)} molecules processed\")\n",
    "    print(f\"Parallel results: {len([r for r in parallel_results if 'error' not in r])} molecules processed\")\n",
    "    print(f\"Cached results: {len(cached_results)} molecules processed\")\n",
    "\n",
    "# Run the benchmark\n",
    "benchmark_processing_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a475c9e",
   "metadata": {},
   "source": [
    "## Challenge 2: Handling Inconsistent LLM Outputs\n",
    "\n",
    "LLMs can produce inconsistent or partially correct chemical information. Here's how to build robust systems that handle these issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ca9a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust Chemical Information Extraction:\n",
      "==================================================\n",
      "\n",
      "Example 1:\n",
      "Input: The compound has SMILES: CC(C)CC1=CC=C(C=C1)C(C)C(=O)O and molecular weight 206.3 Da\n",
      "Extracted SMILES: 1 candidates\n",
      "  Best: CC(C)Cc1ccc(C(C)C(=O)O)cc1 (confidence: 1.00)\n",
      "Molecular Weight: 206.3 (confidence: 0.80)\n",
      "Overall confidence: 0.80\n",
      "------------------------------\n",
      "\n",
      "Example 2:\n",
      "Input: This molecule (c1ccccc1) is benzene, MW: 78.11 g/mol, LogP: 2.13\n",
      "Extracted SMILES: 1 candidates\n",
      "  Best: c1ccccc1 (confidence: 0.80)\n",
      "Molecular Weight: 78.11 (confidence: 0.60)\n",
      "Overall confidence: 0.65\n",
      "------------------------------\n",
      "\n",
      "Example 3:\n",
      "Input: Structure: CCO, ethanol, with 2 H-bond donors and 1 H-bond acceptor\n",
      "Extracted SMILES: 1 candidates\n",
      "  Best: CCO (confidence: 1.00)\n",
      "Overall confidence: 0.00\n",
      "------------------------------\n",
      "\n",
      "Example 4:\n",
      "Input: The SMILES string is probably C1=CC=C(C=C1)C(=O)O but I'm not completely sure about the molecular weight being around 122\n",
      "Extracted SMILES: 1 candidates\n",
      "  Best: O=C(O)c1ccccc1 (confidence: 1.00)\n",
      "Overall confidence: 0.00\n",
      "------------------------------\n",
      "\n",
      "Example 5:\n",
      "Input: Invalid SMILES: XYZ123ABC and some random text with molecular weight 999999 Da\n",
      "Extracted SMILES: 0 candidates\n",
      "Overall confidence: 0.00\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:53:55] SMILES Parse Error: syntax error while parsing: 206.3\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] 206.3\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES '206.3' for input: '206.3'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'compound' for input: 'compound'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'SMILES' for input: 'SMILES'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: molecular\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] molecular\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'molecular' for input: 'molecular'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: 78.11\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] 78.11\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES '78.11' for input: '78.11'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: molecule\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] molecule\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'molecule' for input: 'molecule'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'benzene' for input: 'benzene'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: g/mol\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] g/mol\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'g/mol' for input: 'g/mol'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'Structure' for input: 'Structure'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: ethanol\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] ethanol\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'ethanol' for input: 'ethanol'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: H-bond\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] H-bond\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'H-bond' for input: 'H-bond'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: donors\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] donors\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'donors' for input: 'donors'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'string' for input: 'string'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'SMILES' for input: 'SMILES'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'probably' for input: 'probably'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'completely' for input: 'completely'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: XYZ123ABC\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] XYZ123ABC\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'XYZ123ABC' for input: 'XYZ123ABC'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: 999999\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] 999999\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES '999999' for input: '999999'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'Invalid' for input: 'Invalid'\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'SMILES' for input: 'SMILES'\n",
      "[09:53:55] SMILES Parse Error: syntax error while parsing: random\n",
      "[09:53:55] SMILES Parse Error: check for mistakes around position 1:\n",
      "[09:53:55] random\n",
      "[09:53:55] ^\n",
      "[09:53:55] SMILES Parse Error: Failed parsing SMILES 'random' for input: 'random'\n"
     ]
    }
   ],
   "source": [
    "class RobustChemicalParser:\n",
    "    \"\"\"\n",
    "    A parser that can handle messy, inconsistent LLM outputs and extract\n",
    "    useful chemical information with confidence scoring.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Common patterns for extracting chemical information from text\n",
    "        self.smiles_patterns = [\n",
    "            r'\\b([A-Za-z0-9@+\\-\\[\\]\\(\\)=#$:%\\\\\\/\\.]+)\\b',  # General SMILES pattern\n",
    "            r'SMILES[:\\s]*([A-Za-z0-9@+\\-\\[\\]\\(\\)=#$:%\\\\\\/\\.]+)',  # SMILES: prefix\n",
    "            r'structure[:\\s]*([A-Za-z0-9@+\\-\\[\\]\\(\\)=#$:%\\\\\\/\\.]+)',  # structure: prefix\n",
    "        ]\n",
    "        \n",
    "        self.molecular_weight_patterns = [\n",
    "            r'molecular weight[:\\s]*(\\d+\\.?\\d*)\\s*(?:Da|daltons?|g/mol)?',\n",
    "            r'MW[:\\s]*(\\d+\\.?\\d*)',\n",
    "            r'(\\d+\\.?\\d*)\\s*(?:Da|daltons?|g/mol)',\n",
    "        ]\n",
    "        \n",
    "        self.property_patterns = {\n",
    "            'logp': [r'LogP[:\\s]*(-?\\d+\\.?\\d*)', r'log\\s*P[:\\s]*(-?\\d+\\.?\\d*)'],\n",
    "            'tpsa': [r'TPSA[:\\s]*(\\d+\\.?\\d*)', r'polar surface area[:\\s]*(\\d+\\.?\\d*)'],\n",
    "            'hbd': [r'H-bond donors?[:\\s]*(\\d+)', r'hydrogen bond donors?[:\\s]*(\\d+)'],\n",
    "            'hba': [r'H-bond acceptors?[:\\s]*(\\d+)', r'hydrogen bond acceptors?[:\\s]*(\\d+)'],\n",
    "        }\n",
    "    \n",
    "    def extract_chemical_entities(self, text: str) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Extract chemical entities from potentially messy LLM text output.\n",
    "        Returns results with confidence scores.\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'extracted_smiles': [],\n",
    "            'molecular_weight': None,\n",
    "            'properties': {},\n",
    "            'confidence_scores': {},\n",
    "            'raw_text': text\n",
    "        }\n",
    "        \n",
    "        # Extract SMILES candidates\n",
    "        smiles_candidates = self._extract_smiles_candidates(text)\n",
    "        validated_smiles = []\n",
    "        \n",
    "        for candidate, confidence in smiles_candidates:\n",
    "            validation = validate_smiles_with_details(candidate)\n",
    "            if validation['is_valid']:\n",
    "                validated_smiles.append({\n",
    "                    'smiles': candidate,\n",
    "                    'canonical_smiles': validation['canonical_smiles'],\n",
    "                    'confidence': confidence,\n",
    "                    'properties': validation['properties']\n",
    "                })\n",
    "        \n",
    "        results['extracted_smiles'] = validated_smiles\n",
    "        \n",
    "        # Extract molecular weight\n",
    "        mw_match = self._extract_molecular_weight(text)\n",
    "        if mw_match:\n",
    "            results['molecular_weight'] = mw_match['value']\n",
    "            results['confidence_scores']['molecular_weight'] = mw_match['confidence']\n",
    "        \n",
    "        # Extract other properties\n",
    "        for prop_name, patterns in self.property_patterns.items():\n",
    "            prop_match = self._extract_property(text, patterns)\n",
    "            if prop_match:\n",
    "                results['properties'][prop_name] = prop_match['value']\n",
    "                results['confidence_scores'][prop_name] = prop_match['confidence']\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _extract_smiles_candidates(self, text: str) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Extract SMILES candidates with confidence scores.\"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        for i, pattern in enumerate(self.smiles_patterns):\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                # Basic heuristics for SMILES likelihood\n",
    "                confidence = self._calculate_smiles_confidence(match, pattern_index=i)\n",
    "                if confidence > 0.3:  # Minimum confidence threshold\n",
    "                    candidates.append((match, confidence))\n",
    "        \n",
    "        # Remove duplicates and sort by confidence\n",
    "        seen = set()\n",
    "        unique_candidates = []\n",
    "        for smiles, conf in sorted(candidates, key=lambda x: x[1], reverse=True):\n",
    "            if smiles not in seen:\n",
    "                seen.add(smiles)\n",
    "                unique_candidates.append((smiles, conf))\n",
    "        \n",
    "        return unique_candidates[:5]  # Return top 5 candidates\n",
    "    \n",
    "    def _calculate_smiles_confidence(self, smiles: str, pattern_index: int) -> float:\n",
    "        \"\"\"Calculate confidence score for a SMILES candidate.\"\"\"\n",
    "        confidence = 0.5  # Base confidence\n",
    "        \n",
    "        # Pattern-based confidence adjustment\n",
    "        if pattern_index == 1:  # Explicit SMILES: prefix\n",
    "            confidence += 0.3\n",
    "        elif pattern_index == 2:  # structure: prefix\n",
    "            confidence += 0.2\n",
    "        \n",
    "        # Length-based heuristics\n",
    "        if 5 <= len(smiles) <= 200:\n",
    "            confidence += 0.2\n",
    "        elif len(smiles) < 3 or len(smiles) > 500:\n",
    "            confidence -= 0.3\n",
    "        \n",
    "        # Character composition heuristics\n",
    "        valid_chars = set('CNOSPFClBrIH[]()=@+-.0123456789#\\\\/%$')\n",
    "        if all(c in valid_chars for c in smiles):\n",
    "            confidence += 0.2\n",
    "        \n",
    "        # Common SMILES patterns\n",
    "        if any(pattern in smiles for pattern in ['c1ccccc1', 'CC', 'CN', 'CO']):\n",
    "            confidence += 0.1\n",
    "        \n",
    "        return min(1.0, max(0.0, confidence))\n",
    "    \n",
    "    def _extract_molecular_weight(self, text: str) -> Optional[Dict]:\n",
    "        \"\"\"Extract molecular weight with confidence.\"\"\"\n",
    "        for pattern in self.molecular_weight_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                try:\n",
    "                    value = float(matches[0])\n",
    "                    if 10 <= value <= 5000:  # Reasonable MW range\n",
    "                        return {\n",
    "                            'value': value,\n",
    "                            'confidence': 0.8 if 'molecular weight' in pattern else 0.6\n",
    "                        }\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "    \n",
    "    def _extract_property(self, text: str, patterns: List[str]) -> Optional[Dict]:\n",
    "        \"\"\"Extract a property value with confidence.\"\"\"\n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                try:\n",
    "                    value = float(matches[0])\n",
    "                    return {'value': value, 'confidence': 0.7}\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "    \n",
    "    def cross_validate_extractions(self, text: str) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Cross-validate extracted information against RDKit calculations.\n",
    "        \"\"\"\n",
    "        extraction = self.extract_chemical_entities(text)\n",
    "        validation_results = {\n",
    "            'extraction': extraction,\n",
    "            'validation': {},\n",
    "            'discrepancies': [],\n",
    "            'overall_confidence': 0.0\n",
    "        }\n",
    "        \n",
    "        if extraction['extracted_smiles']:\n",
    "            best_smiles = extraction['extracted_smiles'][0]\n",
    "            mol = Chem.MolFromSmiles(best_smiles['canonical_smiles'])\n",
    "            \n",
    "            if mol:\n",
    "                rdkit_props = extract_molecular_features(mol)\n",
    "                \n",
    "                # Cross-validate molecular weight\n",
    "                if extraction['molecular_weight']:\n",
    "                    rdkit_mw = rdkit_props['molecular_weight']\n",
    "                    extracted_mw = extraction['molecular_weight']\n",
    "                    mw_diff = abs(rdkit_mw - extracted_mw)\n",
    "                    \n",
    "                    if mw_diff < 1.0:\n",
    "                        validation_results['validation']['molecular_weight'] = 'MATCH'\n",
    "                    elif mw_diff < 10.0:\n",
    "                        validation_results['validation']['molecular_weight'] = 'CLOSE'\n",
    "                        validation_results['discrepancies'].append(\n",
    "                            f\"MW discrepancy: extracted={extracted_mw}, calculated={rdkit_mw}\"\n",
    "                        )\n",
    "                    else:\n",
    "                        validation_results['validation']['molecular_weight'] = 'MISMATCH'\n",
    "                        validation_results['discrepancies'].append(\n",
    "                            f\"Major MW discrepancy: extracted={extracted_mw}, calculated={rdkit_mw}\"\n",
    "                        )\n",
    "                \n",
    "                # Cross-validate other properties\n",
    "                for prop in ['logp', 'hbd', 'hba']:\n",
    "                    if prop in extraction['properties']:\n",
    "                        # Add property validation logic here\n",
    "                        pass\n",
    "                \n",
    "                # Calculate overall confidence\n",
    "                confidence_scores = list(extraction['confidence_scores'].values())\n",
    "                if confidence_scores:\n",
    "                    validation_results['overall_confidence'] = sum(confidence_scores) / len(confidence_scores)\n",
    "        \n",
    "        return validation_results\n",
    "\n",
    "# Demonstration with messy LLM outputs\n",
    "parser = RobustChemicalParser()\n",
    "\n",
    "# Simulate various types of messy LLM outputs\n",
    "messy_outputs = [\n",
    "    \"The compound has SMILES: CC(C)CC1=CC=C(C=C1)C(C)C(=O)O and molecular weight 206.3 Da\",\n",
    "    \"This molecule (c1ccccc1) is benzene, MW: 78.11 g/mol, LogP: 2.13\",\n",
    "    \"Structure: CCO, ethanol, with 2 H-bond donors and 1 H-bond acceptor\",\n",
    "    \"The SMILES string is probably C1=CC=C(C=C1)C(=O)O but I'm not completely sure about the molecular weight being around 122\",\n",
    "    \"Invalid SMILES: XYZ123ABC and some random text with molecular weight 999999 Da\",\n",
    "]\n",
    "\n",
    "print(\"Robust Chemical Information Extraction:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, text in enumerate(messy_outputs):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Input: {text}\")\n",
    "    \n",
    "    # Extract and validate\n",
    "    result = parser.cross_validate_extractions(text)\n",
    "    extraction = result['extraction']\n",
    "    \n",
    "    print(f\"Extracted SMILES: {len(extraction['extracted_smiles'])} candidates\")\n",
    "    if extraction['extracted_smiles']:\n",
    "        best = extraction['extracted_smiles'][0]\n",
    "        print(f\"  Best: {best['canonical_smiles']} (confidence: {best['confidence']:.2f})\")\n",
    "    \n",
    "    if extraction['molecular_weight']:\n",
    "        print(f\"Molecular Weight: {extraction['molecular_weight']} (confidence: {extraction['confidence_scores'].get('molecular_weight', 0):.2f})\")\n",
    "    \n",
    "    if result['discrepancies']:\n",
    "        print(f\"Discrepancies: {'; '.join(result['discrepancies'])}\")\n",
    "    \n",
    "    print(f\"Overall confidence: {result['overall_confidence']:.2f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49780f3f",
   "metadata": {},
   "source": [
    "## Challenge 3: Data Quality and Contamination\n",
    "\n",
    "Chemical datasets often contain errors, duplicates, and inconsistencies. Here's how to build quality control systems:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbcc87",
   "metadata": {},
   "source": [
    "> **NOTE FROM GREG**: I needed to add an import to the following block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical Data Quality Control Demonstration\n",
      "==================================================\n",
      "Test dataset created with 12 entries\n",
      "Running comprehensive data quality checks...\n",
      "  Valid structures: 10/12\n",
      "  Checking for duplicates...\n",
      "  Detecting structural outliers...\n",
      "  Checking text-structure consistency...\n",
      "  Detecting suspicious patterns...\n",
      "  Creating cleaned dataset...\n",
      "\n",
      "Quality Control Results:\n",
      "Original dataset size: 12\n",
      "Cleaned dataset size: 6\n",
      "Removal rate: 50.0%\n",
      "\n",
      "Issues Found:\n",
      "  Duplicates: 10 cases\n",
      "  Invalid Smiles: 2 cases\n",
      "  Structural Outliers: 3 cases\n",
      "  Text Inconsistencies: 2 cases\n",
      "  Suspicious Patterns: 6 cases\n",
      "\n",
      "Recommendations:\n",
      "  1. Remove 4 exact duplicate structures\n",
      "  2. Review 6 near-duplicate pairs (similarity > 0.8)\n",
      "  3. High removal rate (50.0%) suggests significant data quality issues\n",
      "  4. Review structural outliers - they may indicate data entry errors\n",
      "  5. Text descriptions inconsistent with structures - consider regenerating descriptions\n",
      "\n",
      "First 3 entries of cleaned dataset:\n",
      "  1. Ethanol: CCO\n",
      "  2. Benzene: c1ccccc1\n",
      "  3. Very long chain: CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:55:35] SMILES Parse Error: Failed parsing SMILES 'INVALID123' for input: 'INVALID123'\n",
      "[09:55:35] SMILES Parse Error: unclosed ring for input: 'C1CCC'\n"
     ]
    }
   ],
   "source": [
    "# EDIT BY GREG: add missing import\n",
    "from rdkit import DataStructs\n",
    "\n",
    "class ChemicalDataQualityController:\n",
    "    \"\"\"\n",
    "    A comprehensive system for detecting and handling data quality issues\n",
    "    in chemical datasets used for LLM training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold: float = 0.85):\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.quality_stats = {\n",
    "            'total_processed': 0,\n",
    "            'duplicates_found': 0,\n",
    "            'invalid_structures': 0,\n",
    "            'outliers_detected': 0,\n",
    "            'cleaned_structures': 0\n",
    "        }\n",
    "    \n",
    "    def comprehensive_quality_check(self, data: List[Dict]) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Perform comprehensive quality checks on chemical dataset.\n",
    "        \n",
    "        Args:\n",
    "            data: List of dictionaries with 'smiles' and optional 'name', 'description' keys\n",
    "        \n",
    "        Returns:\n",
    "            Quality report with flagged issues and cleaned data\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            'original_size': len(data),\n",
    "            'issues': {\n",
    "                'duplicates': [],\n",
    "                'invalid_smiles': [],\n",
    "                'structural_outliers': [],\n",
    "                'text_inconsistencies': [],\n",
    "                'suspicious_patterns': []\n",
    "            },\n",
    "            'cleaned_data': [],\n",
    "            'recommendations': []\n",
    "        }\n",
    "        \n",
    "        print(\"Running comprehensive data quality checks...\")\n",
    "        \n",
    "        # Step 1: Basic validation and cleaning\n",
    "        valid_entries = []\n",
    "        for i, entry in enumerate(data):\n",
    "            smiles = entry.get('smiles', '')\n",
    "            validation = validate_smiles_with_details(smiles)\n",
    "            \n",
    "            if validation['is_valid']:\n",
    "                # Store canonical SMILES for consistency\n",
    "                entry['canonical_smiles'] = validation['canonical_smiles']\n",
    "                entry['original_index'] = i\n",
    "                valid_entries.append(entry)\n",
    "            else:\n",
    "                report['issues']['invalid_smiles'].append({\n",
    "                    'index': i,\n",
    "                    'smiles': smiles,\n",
    "                    'errors': validation['errors']\n",
    "                })\n",
    "        \n",
    "        print(f\"  Valid structures: {len(valid_entries)}/{len(data)}\")\n",
    "        \n",
    "        # Step 2: Duplicate detection\n",
    "        duplicates = self._find_duplicates(valid_entries)\n",
    "        report['issues']['duplicates'] = duplicates\n",
    "        \n",
    "        # Step 3: Structural outlier detection\n",
    "        outliers = self._detect_structural_outliers(valid_entries)\n",
    "        report['issues']['structural_outliers'] = outliers\n",
    "        \n",
    "        # Step 4: Text-structure consistency checks\n",
    "        if any('description' in entry for entry in valid_entries):\n",
    "            inconsistencies = self._check_text_structure_consistency(valid_entries)\n",
    "            report['issues']['text_inconsistencies'] = inconsistencies\n",
    "        \n",
    "        # Step 5: Suspicious pattern detection\n",
    "        suspicious = self._detect_suspicious_patterns(valid_entries)\n",
    "        report['issues']['suspicious_patterns'] = suspicious\n",
    "        \n",
    "        # Step 6: Create cleaned dataset\n",
    "        cleaned_data = self._create_cleaned_dataset(valid_entries, report['issues'])\n",
    "        report['cleaned_data'] = cleaned_data\n",
    "        report['final_size'] = len(cleaned_data)\n",
    "        \n",
    "        # Step 7: Generate recommendations\n",
    "        report['recommendations'] = self._generate_recommendations(report)\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _find_duplicates(self, entries: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Find duplicate structures using canonical SMILES and similarity.\"\"\"\n",
    "        print(\"  Checking for duplicates...\")\n",
    "        \n",
    "        duplicates = []\n",
    "        seen_smiles = {}\n",
    "        \n",
    "        # Exact duplicates (same canonical SMILES)\n",
    "        for entry in entries:\n",
    "            canonical = entry['canonical_smiles']\n",
    "            if canonical in seen_smiles:\n",
    "                duplicates.append({\n",
    "                    'type': 'exact_duplicate',\n",
    "                    'indices': [seen_smiles[canonical]['original_index'], entry['original_index']],\n",
    "                    'smiles': canonical,\n",
    "                    'names': [seen_smiles[canonical].get('name', 'Unknown'), \n",
    "                             entry.get('name', 'Unknown')]\n",
    "                })\n",
    "            else:\n",
    "                seen_smiles[canonical] = entry\n",
    "        \n",
    "        # Near-duplicates (high structural similarity)\n",
    "        if len(entries) < 1000:  # Only for smaller datasets due to O(n²) complexity\n",
    "            fingerprints = []\n",
    "            for entry in entries:\n",
    "                mol = Chem.MolFromSmiles(entry['canonical_smiles'])\n",
    "                if mol:\n",
    "                    fp = Chem.RDKFingerprint(mol)\n",
    "                    fingerprints.append((entry, fp))\n",
    "            \n",
    "            for i, (entry1, fp1) in enumerate(fingerprints):\n",
    "                for j, (entry2, fp2) in enumerate(fingerprints[i+1:], i+1):\n",
    "                    similarity = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "                    if similarity > self.similarity_threshold:\n",
    "                        duplicates.append({\n",
    "                            'type': 'near_duplicate',\n",
    "                            'similarity': similarity,\n",
    "                            'indices': [entry1['original_index'], entry2['original_index']],\n",
    "                            'smiles': [entry1['canonical_smiles'], entry2['canonical_smiles']],\n",
    "                            'names': [entry1.get('name', 'Unknown'), entry2.get('name', 'Unknown')]\n",
    "                        })\n",
    "        \n",
    "        return duplicates\n",
    "    \n",
    "    def _detect_structural_outliers(self, entries: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Detect structural outliers that might indicate data quality issues.\"\"\"\n",
    "        print(\"  Detecting structural outliers...\")\n",
    "        \n",
    "        outliers = []\n",
    "        properties = []\n",
    "        \n",
    "        # Calculate properties for all molecules\n",
    "        for entry in entries:\n",
    "            mol = Chem.MolFromSmiles(entry['canonical_smiles'])\n",
    "            if mol:\n",
    "                props = {\n",
    "                    'mw': Descriptors.MolWt(mol),\n",
    "                    'logp': Descriptors.MolLogP(mol),\n",
    "                    'num_atoms': mol.GetNumAtoms(),\n",
    "                    'num_rings': rdMolDescriptors.CalcNumRings(mol),\n",
    "                    'entry': entry\n",
    "                }\n",
    "                properties.append(props)\n",
    "        \n",
    "        if not properties:\n",
    "            return outliers\n",
    "        \n",
    "        # Statistical outlier detection using IQR method\n",
    "        for prop_name in ['mw', 'logp', 'num_atoms', 'num_rings']:\n",
    "            values = [p[prop_name] for p in properties]\n",
    "            q1 = pd.Series(values).quantile(0.25)\n",
    "            q3 = pd.Series(values).quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            \n",
    "            lower_bound = q1 - 3 * iqr  # More permissive than standard 1.5*IQR\n",
    "            upper_bound = q3 + 3 * iqr\n",
    "            \n",
    "            for props in properties:\n",
    "                value = props[prop_name]\n",
    "                if value < lower_bound or value > upper_bound:\n",
    "                    outliers.append({\n",
    "                        'type': f'{prop_name}_outlier',\n",
    "                        'index': props['entry']['original_index'],\n",
    "                        'smiles': props['entry']['canonical_smiles'],\n",
    "                        'property': prop_name,\n",
    "                        'value': value,\n",
    "                        'expected_range': f'{lower_bound:.1f} - {upper_bound:.1f}'\n",
    "                    })\n",
    "        \n",
    "        return outliers\n",
    "    \n",
    "    def _check_text_structure_consistency(self, entries: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Check consistency between text descriptions and calculated properties.\"\"\"\n",
    "        print(\"  Checking text-structure consistency...\")\n",
    "        \n",
    "        inconsistencies = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            if 'description' not in entry:\n",
    "                continue\n",
    "            \n",
    "            description = entry['description'].lower()\n",
    "            mol = Chem.MolFromSmiles(entry['canonical_smiles'])\n",
    "            if not mol:\n",
    "                continue\n",
    "            \n",
    "            features = extract_molecular_features(mol)\n",
    "            \n",
    "            # Check molecular weight consistency\n",
    "            if 'molecular weight' in description or 'mw' in description:\n",
    "                # Extract numbers that might be molecular weights\n",
    "                mw_numbers = re.findall(r'\\b(\\d{2,4}(?:\\.\\d+)?)\\b', description)\n",
    "                actual_mw = features['molecular_weight']\n",
    "                \n",
    "                found_matching_mw = False\n",
    "                for num_str in mw_numbers:\n",
    "                    try:\n",
    "                        described_mw = float(num_str)\n",
    "                        if abs(described_mw - actual_mw) < 5:  # 5 Da tolerance\n",
    "                            found_matching_mw = True\n",
    "                            break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                \n",
    "                if not found_matching_mw and mw_numbers:\n",
    "                    inconsistencies.append({\n",
    "                        'type': 'molecular_weight_mismatch',\n",
    "                        'index': entry['original_index'],\n",
    "                        'smiles': entry['canonical_smiles'],\n",
    "                        'described_mw': mw_numbers,\n",
    "                        'calculated_mw': actual_mw,\n",
    "                        'description_excerpt': description[:100] + '...'\n",
    "                    })\n",
    "            \n",
    "            # Check functional group mentions\n",
    "            mentioned_groups = []\n",
    "            if 'alcohol' in description:\n",
    "                mentioned_groups.append('alcohol')\n",
    "            if 'carboxylic acid' in description or 'carboxyl' in description:\n",
    "                mentioned_groups.append('carboxylic_acid')\n",
    "            if 'amine' in description:\n",
    "                mentioned_groups.append('amine')\n",
    "            if 'aromatic' in description or 'benzene' in description:\n",
    "                mentioned_groups.append('aromatic')\n",
    "            \n",
    "            detected_groups = [fg.split('(')[0] for fg in features.get('functional_groups', [])]\n",
    "            \n",
    "            for mentioned in mentioned_groups:\n",
    "                if mentioned not in detected_groups and mentioned != 'aromatic':\n",
    "                    inconsistencies.append({\n",
    "                        'type': 'functional_group_mismatch',\n",
    "                        'index': entry['original_index'],\n",
    "                        'smiles': entry['canonical_smiles'],\n",
    "                        'mentioned_group': mentioned,\n",
    "                        'detected_groups': detected_groups,\n",
    "                        'description_excerpt': description[:100] + '...'\n",
    "                    })\n",
    "        \n",
    "        return inconsistencies\n",
    "    \n",
    "    def _detect_suspicious_patterns(self, entries: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Detect suspicious patterns that might indicate synthetic or corrupted data.\"\"\"\n",
    "        print(\"  Detecting suspicious patterns...\")\n",
    "        \n",
    "        suspicious = []\n",
    "        \n",
    "        # Pattern 1: Repetitive SMILES patterns\n",
    "        smiles_parts = {}\n",
    "        for entry in entries:\n",
    "            smiles = entry['canonical_smiles']\n",
    "            # Look for repeated substrings\n",
    "            for length in [3, 4, 5]:\n",
    "                for i in range(len(smiles) - length + 1):\n",
    "                    substring = smiles[i:i+length]\n",
    "                    if substring.count(substring[0]) != len(substring):  # Not all same character\n",
    "                        smiles_parts[substring] = smiles_parts.get(substring, 0) + 1\n",
    "        \n",
    "        # Flag SMILES with highly repetitive patterns\n",
    "        for entry in entries:\n",
    "            smiles = entry['canonical_smiles']\n",
    "            repetitive_score = 0\n",
    "            for substring, count in smiles_parts.items():\n",
    "                if count > len(entries) * 0.1 and substring in smiles:  # Appears in >10% of dataset\n",
    "                    repetitive_score += count\n",
    "            \n",
    "            if repetitive_score > len(entries) * 0.2:\n",
    "                suspicious.append({\n",
    "                    'type': 'repetitive_smiles_pattern',\n",
    "                    'index': entry['original_index'],\n",
    "                    'smiles': smiles,\n",
    "                    'repetitive_score': repetitive_score\n",
    "                })\n",
    "        \n",
    "        # Pattern 2: Unrealistic property combinations\n",
    "        for entry in entries:\n",
    "            mol = Chem.MolFromSmiles(entry['canonical_smiles'])\n",
    "            if mol:\n",
    "                mw = Descriptors.MolWt(mol)\n",
    "                num_atoms = mol.GetNumAtoms()\n",
    "                \n",
    "                # Flag extremely dense molecules (too much mass for number of atoms)\n",
    "                if num_atoms > 0 and mw / num_atoms > 50:  # Average atomic weight > 50\n",
    "                    suspicious.append({\n",
    "                        'type': 'unrealistic_density',\n",
    "                        'index': entry['original_index'],\n",
    "                        'smiles': entry['canonical_smiles'],\n",
    "                        'mw_per_atom': mw / num_atoms\n",
    "                    })\n",
    "        \n",
    "        return suspicious\n",
    "    \n",
    "    def _create_cleaned_dataset(self, entries: List[Dict], issues: Dict) -> List[Dict]:\n",
    "        \"\"\"Create a cleaned dataset by removing problematic entries.\"\"\"\n",
    "        print(\"  Creating cleaned dataset...\")\n",
    "        \n",
    "        # Collect indices to remove\n",
    "        indices_to_remove = set()\n",
    "        \n",
    "        # Remove exact duplicates (keep first occurrence)\n",
    "        for dup in issues['duplicates']:\n",
    "            if dup['type'] == 'exact_duplicate':\n",
    "                indices_to_remove.add(dup['indices'][1])  # Remove second occurrence\n",
    "        \n",
    "        # Remove severe outliers\n",
    "        for outlier in issues['structural_outliers']:\n",
    "            if outlier['type'] in ['num_atoms_outlier', 'mw_outlier']:\n",
    "                # Only remove extreme outliers\n",
    "                if outlier['type'] == 'num_atoms_outlier' and outlier['value'] > 200:\n",
    "                    indices_to_remove.add(outlier['index'])\n",
    "                elif outlier['type'] == 'mw_outlier' and outlier['value'] > 2000:\n",
    "                    indices_to_remove.add(outlier['index'])\n",
    "        \n",
    "        # Remove highly suspicious entries\n",
    "        for susp in issues['suspicious_patterns']:\n",
    "            if susp['type'] == 'unrealistic_density' and susp['mw_per_atom'] > 100:\n",
    "                indices_to_remove.add(susp['index'])\n",
    "        \n",
    "        # Create cleaned dataset\n",
    "        cleaned = []\n",
    "        for entry in entries:\n",
    "            if entry['original_index'] not in indices_to_remove:\n",
    "                # Clean up the entry\n",
    "                cleaned_entry = {\n",
    "                    'smiles': entry['canonical_smiles'],  # Use canonical form\n",
    "                    'name': entry.get('name', ''),\n",
    "                    'description': entry.get('description', '')\n",
    "                }\n",
    "                cleaned.append(cleaned_entry)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def _generate_recommendations(self, report: Dict) -> List[str]:\n",
    "        \"\"\"Generate recommendations based on quality issues found.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # Duplicate recommendations\n",
    "        if report['issues']['duplicates']:\n",
    "            exact_dups = len([d for d in report['issues']['duplicates'] if d['type'] == 'exact_duplicate'])\n",
    "            near_dups = len([d for d in report['issues']['duplicates'] if d['type'] == 'near_duplicate'])\n",
    "            \n",
    "            if exact_dups > 0:\n",
    "                recommendations.append(f\"Remove {exact_dups} exact duplicate structures\")\n",
    "            if near_dups > 0:\n",
    "                recommendations.append(f\"Review {near_dups} near-duplicate pairs (similarity > {self.similarity_threshold})\")\n",
    "        \n",
    "        # Data size recommendations\n",
    "        removal_rate = (report['original_size'] - report['final_size']) / report['original_size']\n",
    "        if removal_rate > 0.2:\n",
    "            recommendations.append(f\"High removal rate ({removal_rate:.1%}) suggests significant data quality issues\")\n",
    "        \n",
    "        # Outlier recommendations\n",
    "        if report['issues']['structural_outliers']:\n",
    "            recommendations.append(\"Review structural outliers - they may indicate data entry errors\")\n",
    "        \n",
    "        # Consistency recommendations\n",
    "        if report['issues']['text_inconsistencies']:\n",
    "            recommendations.append(\"Text descriptions inconsistent with structures - consider regenerating descriptions\")\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations.append(\"Dataset quality looks good! No major issues detected.\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Demonstration with a problematic dataset\n",
    "def create_test_dataset_with_issues():\n",
    "    \"\"\"Create a test dataset with various quality issues for demonstration.\"\"\"\n",
    "    return [\n",
    "        # Good entries\n",
    "        {'smiles': 'CCO', 'name': 'Ethanol', 'description': 'Ethanol is an alcohol with molecular weight 46.07 Da'},\n",
    "        {'smiles': 'c1ccccc1', 'name': 'Benzene', 'description': 'Benzene is an aromatic compound'},\n",
    "        \n",
    "        # Duplicates\n",
    "        {'smiles': 'CCO', 'name': 'Ethyl alcohol', 'description': 'Another entry for ethanol'},  # Exact duplicate\n",
    "        {'smiles': 'c1ccccc1', 'name': 'Benzene ring', 'description': 'Benzene ring structure'},  # Exact duplicate\n",
    "        \n",
    "        # Invalid SMILES\n",
    "        {'smiles': 'INVALID123', 'name': 'Bad entry', 'description': 'This is not a valid SMILES'},\n",
    "        {'smiles': 'C1CCC', 'name': 'Unclosed ring', 'description': 'Missing ring closure'},\n",
    "        \n",
    "        # Outliers\n",
    "        {'smiles': 'C' * 100, 'name': 'Very long chain', 'description': 'Extremely long alkyl chain'},\n",
    "        \n",
    "        # Text inconsistencies\n",
    "        {'smiles': 'CCO', 'name': 'Ethanol', 'description': 'This alcohol has molecular weight 200 Da'},  # Wrong MW\n",
    "        {'smiles': 'c1ccccc1', 'name': 'Benzene', 'description': 'Contains carboxylic acid groups'},  # Wrong functional group\n",
    "        \n",
    "        # Near duplicates\n",
    "        {'smiles': 'CC(C)O', 'name': 'Isopropanol', 'description': 'Isopropyl alcohol'},\n",
    "        \n",
    "        # Good entries for padding\n",
    "        {'smiles': 'CC(=O)O', 'name': 'Acetic acid', 'description': 'Acetic acid is a carboxylic acid'},\n",
    "        {'smiles': 'CN', 'name': 'Methylamine', 'description': 'Simple amine compound'},\n",
    "    ]\n",
    "\n",
    "# Run quality control demonstration\n",
    "print(\"Chemical Data Quality Control Demonstration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create test dataset with known issues\n",
    "test_data = create_test_dataset_with_issues()\n",
    "print(f\"Test dataset created with {len(test_data)} entries\")\n",
    "\n",
    "# Run quality control\n",
    "qc = ChemicalDataQualityController(similarity_threshold=0.8)\n",
    "quality_report = qc.comprehensive_quality_check(test_data)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nQuality Control Results:\")\n",
    "print(f\"Original dataset size: {quality_report['original_size']}\")\n",
    "print(f\"Cleaned dataset size: {quality_report['final_size']}\")\n",
    "print(f\"Removal rate: {(1 - quality_report['final_size']/quality_report['original_size'])*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nIssues Found:\")\n",
    "for issue_type, issues in quality_report['issues'].items():\n",
    "    if issues:\n",
    "        print(f\"  {issue_type.replace('_', ' ').title()}: {len(issues)} cases\")\n",
    "\n",
    "print(f\"\\nRecommendations:\")\n",
    "for i, rec in enumerate(quality_report['recommendations'], 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "# Show example of cleaned data\n",
    "print(f\"\\nFirst 3 entries of cleaned dataset:\")\n",
    "for i, entry in enumerate(quality_report['cleaned_data'][:3]):\n",
    "    print(f\"  {i+1}. {entry['name']}: {entry['smiles']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1832a5",
   "metadata": {},
   "source": [
    "### Advanced Contamination Detection\n",
    "\n",
    "> **NOTE FROM GREG**: the following section of code does not work. I'm leaving it here as the first example of something that didn't actually work as generated by the LLM.\n",
    "\n",
    "\n",
    "Data contamination is a critical issue when training LLMs on chemical data. Beyond basic quality checks, sophisticated contamination detection is essential:\n",
    "\n",
    "**Cross-Dataset Leakage Detection:**\n",
    "```python\n",
    "def detect_cross_dataset_leakage(train_smiles, test_smiles, validation_smiles):\n",
    "    \"\"\"Detect potential data leakage between training, test, and validation sets\"\"\"\n",
    "    # Implementation would check for exact matches and high-similarity compounds\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Temporal Contamination:**\n",
    "Chemical databases often contain compounds discovered after certain dates. For historically-aware models, ensure temporal consistency:\n",
    "\n",
    "**Vendor Catalog Contamination:**\n",
    "Many \"novel\" compounds in datasets are actually from commercial catalogs, which can lead to unrealistic performance expectations.\n",
    "\n",
    "**Synthetic Accessibility Bias:**\n",
    "Datasets often over-represent easily synthesizable compounds, creating bias in LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b0e445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamination Detection Demonstration\n",
      "========================================\n",
      "Detecting cross-dataset contamination...\n",
      "  train: 5 valid structures\n",
      "  test: 3 valid structures\n",
      "  validation: 3 valid structures\n",
      "\n",
      "Contamination Analysis Results:\n",
      "Contamination severity: moderate\n",
      "Total exact overlaps: 2\n",
      "\n",
      "Exact overlaps found:\n",
      "  train_vs_test: 1 compounds (20.0% of first dataset)\n",
      "    Examples: ['CCO']\n",
      "  train_vs_validation: 1 compounds (20.0% of first dataset)\n",
      "    Examples: ['CC(=O)O']\n",
      "\n",
      "Recommendations:\n",
      "  1. Moderate contamination detected - remove overlapping compounds\n",
      "  2. Remove 1 overlapping compounds between train_vs_test\n",
      "  3. Remove 1 overlapping compounds between train_vs_validation\n",
      "\n",
      "Temporal Contamination Check:\n",
      "Checking for temporal contamination (compounds after 2020-01-01)...\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "Python argument types in\n    rdkit.Chem.rdMolDescriptors.GetUSRScore(Mol)\ndid not match C++ signature:\n    GetUSRScore(boost::python::api::object descriptor1, boost::python::api::object descriptor2, boost::python::api::object weights=[])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 271\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Test temporal contamination detection\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTemporal Contamination Check:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m temporal_results \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_temporal_contamination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuspicious compounds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemporal_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuspicious_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Test vendor bias detection\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 122\u001b[0m, in \u001b[0;36mContaminationDetector.detect_temporal_contamination\u001b[0;34m(self, smiles_list, target_date)\u001b[0m\n\u001b[1;32m    119\u001b[0m mol \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mMolFromSmiles(smiles)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mol:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# Example heuristic: very complex molecules might be recent\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     complexity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_molecular_complexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m complexity_score \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m20\u001b[39m:  \u001b[38;5;66;03m# Arbitrary threshold\u001b[39;00m\n\u001b[1;32m    124\u001b[0m         suspicious_compounds\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmiles\u001b[39m\u001b[38;5;124m'\u001b[39m: smiles,\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplexity_score\u001b[39m\u001b[38;5;124m'\u001b[39m: complexity_score,\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreason\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_complexity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         })\n",
      "Cell \u001b[0;32mIn[15], line 188\u001b[0m, in \u001b[0;36mContaminationDetector._calculate_molecular_complexity\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m    186\u001b[0m complexity \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rdMolDescriptors\u001b[38;5;241m.\u001b[39mCalcNumRings(mol) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    187\u001b[0m complexity \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rdMolDescriptors\u001b[38;5;241m.\u001b[39mCalcNumHeteroatoms(mol) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[0;32m--> 188\u001b[0m complexity \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mrdMolDescriptors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetUSRScore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmol\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(rdMolDescriptors, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGetUSRScore\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m complexity\n",
      "\u001b[0;31mArgumentError\u001b[0m: Python argument types in\n    rdkit.Chem.rdMolDescriptors.GetUSRScore(Mol)\ndid not match C++ signature:\n    GetUSRScore(boost::python::api::object descriptor1, boost::python::api::object descriptor2, boost::python::api::object weights=[])"
     ]
    }
   ],
   "source": [
    "class ContaminationDetector:\n",
    "    \"\"\"\n",
    "    Advanced contamination detection for chemical datasets used in LLM training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold: float = 0.85):\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "    \n",
    "    def detect_cross_dataset_leakage(self, datasets: Dict[str, List[str]]) -> Dict:\n",
    "        \"\"\"\n",
    "        Detect potential data leakage between multiple datasets.\n",
    "        \n",
    "        Args:\n",
    "            datasets: Dictionary with dataset names as keys and lists of SMILES as values\n",
    "                     e.g., {'train': [...], 'test': [...], 'validation': [...]}\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with contamination analysis results\n",
    "        \"\"\"\n",
    "        print(\"Detecting cross-dataset contamination...\")\n",
    "        \n",
    "        results = {\n",
    "            'exact_overlaps': {},\n",
    "            'similarity_overlaps': {},\n",
    "            'summary': {}\n",
    "        }\n",
    "        \n",
    "        # Convert SMILES to canonical form and create fingerprints\n",
    "        canonical_datasets = {}\n",
    "        fingerprint_datasets = {}\n",
    "        \n",
    "        for name, smiles_list in datasets.items():\n",
    "            canonical_smiles = []\n",
    "            fingerprints = []\n",
    "            \n",
    "            for smiles in smiles_list:\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol:\n",
    "                    canonical = Chem.MolToSmiles(mol)\n",
    "                    canonical_smiles.append(canonical)\n",
    "                    fingerprints.append(Chem.RDKFingerprint(mol))\n",
    "            \n",
    "            canonical_datasets[name] = canonical_smiles\n",
    "            fingerprint_datasets[name] = fingerprints\n",
    "            print(f\"  {name}: {len(canonical_smiles)} valid structures\")\n",
    "        \n",
    "        # Check exact overlaps\n",
    "        dataset_names = list(datasets.keys())\n",
    "        for i, name1 in enumerate(dataset_names):\n",
    "            for name2 in dataset_names[i+1:]:\n",
    "                overlap_key = f\"{name1}_vs_{name2}\"\n",
    "                \n",
    "                set1 = set(canonical_datasets[name1])\n",
    "                set2 = set(canonical_datasets[name2])\n",
    "                exact_overlap = set1.intersection(set2)\n",
    "                \n",
    "                results['exact_overlaps'][overlap_key] = {\n",
    "                    'count': len(exact_overlap),\n",
    "                    'percentage_of_first': len(exact_overlap) / len(set1) * 100 if set1 else 0,\n",
    "                    'percentage_of_second': len(exact_overlap) / len(set2) * 100 if set2 else 0,\n",
    "                    'overlapping_smiles': list(exact_overlap)[:10]  # First 10 examples\n",
    "                }\n",
    "        \n",
    "        # Check similarity-based overlaps (computationally expensive, limited to smaller datasets)\n",
    "        for i, name1 in enumerate(dataset_names):\n",
    "            for name2 in dataset_names[i+1:]:\n",
    "                overlap_key = f\"{name1}_vs_{name2}\"\n",
    "                \n",
    "                if len(fingerprint_datasets[name1]) < 1000 and len(fingerprint_datasets[name2]) < 1000:\n",
    "                    similar_pairs = []\n",
    "                    \n",
    "                    for idx1, fp1 in enumerate(fingerprint_datasets[name1]):\n",
    "                        for idx2, fp2 in enumerate(fingerprint_datasets[name2]):\n",
    "                            similarity = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "                            if similarity > self.similarity_threshold:\n",
    "                                similar_pairs.append({\n",
    "                                    'smiles1': canonical_datasets[name1][idx1],\n",
    "                                    'smiles2': canonical_datasets[name2][idx2],\n",
    "                                    'similarity': similarity\n",
    "                                })\n",
    "                    \n",
    "                    results['similarity_overlaps'][overlap_key] = {\n",
    "                        'count': len(similar_pairs),\n",
    "                        'pairs': similar_pairs[:5]  # First 5 examples\n",
    "                    }\n",
    "                else:\n",
    "                    results['similarity_overlaps'][overlap_key] = {\n",
    "                        'count': 'skipped_large_dataset',\n",
    "                        'note': 'Dataset too large for pairwise comparison'\n",
    "                    }\n",
    "        \n",
    "        # Generate summary\n",
    "        total_exact_overlaps = sum(result['count'] for result in results['exact_overlaps'].values() \n",
    "                                 if isinstance(result['count'], int))\n",
    "        \n",
    "        results['summary'] = {\n",
    "            'total_exact_overlaps': total_exact_overlaps,\n",
    "            'datasets_analyzed': len(datasets),\n",
    "            'contamination_severity': self._assess_contamination_severity(results),\n",
    "            'recommendations': self._generate_contamination_recommendations(results)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def detect_temporal_contamination(self, smiles_list: List[str], \n",
    "                                    target_date: str = \"2020-01-01\") -> Dict:\n",
    "        \"\"\"\n",
    "        Detect compounds that might be from after a target date.\n",
    "        Note: This is a simplified version - real implementation would require\n",
    "        a database of compound discovery/publication dates.\n",
    "        \"\"\"\n",
    "        print(f\"Checking for temporal contamination (compounds after {target_date})...\")\n",
    "        \n",
    "        # This is a placeholder implementation\n",
    "        # In practice, you'd need a database mapping SMILES to discovery dates\n",
    "        suspicious_compounds = []\n",
    "        \n",
    "        for smiles in smiles_list:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                # Example heuristic: very complex molecules might be recent\n",
    "                complexity_score = self._calculate_molecular_complexity(mol)\n",
    "                if complexity_score > 20:  # Arbitrary threshold\n",
    "                    suspicious_compounds.append({\n",
    "                        'smiles': smiles,\n",
    "                        'complexity_score': complexity_score,\n",
    "                        'reason': 'high_complexity'\n",
    "                    })\n",
    "        \n",
    "        return {\n",
    "            'suspicious_count': len(suspicious_compounds),\n",
    "            'suspicious_compounds': suspicious_compounds[:10],\n",
    "            'recommendation': f\"Manual review recommended for {len(suspicious_compounds)} complex compounds\"\n",
    "        }\n",
    "    \n",
    "    def detect_vendor_catalog_bias(self, smiles_list: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Detect potential bias from commercial compound catalogs.\n",
    "        \"\"\"\n",
    "        print(\"Detecting vendor catalog bias...\")\n",
    "        \n",
    "        # Common patterns in commercial compounds\n",
    "        vendor_patterns = {\n",
    "            'simple_aromatics': r'c1ccccc1',  # Simple benzene rings\n",
    "            'common_protecting_groups': r'C\\(=O\\)OC\\(C\\)\\(C\\)C',  # Boc groups\n",
    "            'standard_linkers': r'OCCOCCOC',  # PEG-like linkers\n",
    "        }\n",
    "        \n",
    "        pattern_counts = {pattern: 0 for pattern in vendor_patterns.keys()}\n",
    "        flagged_compounds = []\n",
    "        \n",
    "        for smiles in smiles_list:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol:\n",
    "                # Check for overly simple structures\n",
    "                if mol.GetNumAtoms() < 10 and mol.GetNumBonds() < 10:\n",
    "                    flagged_compounds.append({\n",
    "                        'smiles': smiles,\n",
    "                        'reason': 'overly_simple',\n",
    "                        'num_atoms': mol.GetNumAtoms()\n",
    "                    })\n",
    "                \n",
    "                # Check for common patterns\n",
    "                for pattern_name, pattern in vendor_patterns.items():\n",
    "                    if re.search(pattern, smiles):\n",
    "                        pattern_counts[pattern_name] += 1\n",
    "        \n",
    "        return {\n",
    "            'pattern_counts': pattern_counts,\n",
    "            'flagged_simple': len(flagged_compounds),\n",
    "            'total_analyzed': len(smiles_list),\n",
    "            'bias_indicators': {\n",
    "                'high_simple_proportion': len(flagged_compounds) / len(smiles_list) > 0.3,\n",
    "                'pattern_dominance': any(count > len(smiles_list) * 0.2 for count in pattern_counts.values())\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _calculate_molecular_complexity(self, mol) -> float:\n",
    "        \"\"\"Calculate a simple molecular complexity score.\"\"\"\n",
    "        if not mol:\n",
    "            return 0\n",
    "        \n",
    "        complexity = 0\n",
    "        complexity += mol.GetNumAtoms() * 0.1\n",
    "        complexity += mol.GetNumBonds() * 0.1\n",
    "        complexity += rdMolDescriptors.CalcNumRings(mol) * 2\n",
    "        complexity += rdMolDescriptors.CalcNumHeteroatoms(mol) * 1.5\n",
    "        complexity += len(rdMolDescriptors.GetUSRScore(mol)) * 0.01 if hasattr(rdMolDescriptors, 'GetUSRScore') else 0\n",
    "        \n",
    "        return complexity\n",
    "    \n",
    "    def _assess_contamination_severity(self, results: Dict) -> str:\n",
    "        \"\"\"Assess the overall severity of contamination.\"\"\"\n",
    "        exact_overlaps = sum(result['count'] for result in results['exact_overlaps'].values() \n",
    "                           if isinstance(result['count'], int))\n",
    "        \n",
    "        if exact_overlaps == 0:\n",
    "            return \"low\"\n",
    "        elif exact_overlaps < 10:\n",
    "            return \"moderate\"\n",
    "        else:\n",
    "            return \"high\"\n",
    "    \n",
    "    def _generate_contamination_recommendations(self, results: Dict) -> List[str]:\n",
    "        \"\"\"Generate recommendations based on contamination analysis.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        severity = self._assess_contamination_severity(results)\n",
    "        \n",
    "        if severity == \"high\":\n",
    "            recommendations.append(\"CRITICAL: High level of contamination detected - review data splitting strategy\")\n",
    "            recommendations.append(\"Consider using scaffold-based or time-based splitting instead of random splitting\")\n",
    "        elif severity == \"moderate\":\n",
    "            recommendations.append(\"Moderate contamination detected - remove overlapping compounds\")\n",
    "        else:\n",
    "            recommendations.append(\"Low contamination level - acceptable for most applications\")\n",
    "        \n",
    "        # Check for specific issues\n",
    "        for overlap_key, overlap_data in results['exact_overlaps'].items():\n",
    "            if overlap_data['count'] > 0:\n",
    "                recommendations.append(f\"Remove {overlap_data['count']} overlapping compounds between {overlap_key}\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Demonstration of contamination detection\n",
    "print(\"Contamination Detection Demonstration\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create example datasets with known contamination\n",
    "example_datasets = {\n",
    "    'train': [\n",
    "        'CCO',  # ethanol\n",
    "        'c1ccccc1',  # benzene\n",
    "        'CC(=O)O',  # acetic acid\n",
    "        'CC(C)O',  # isopropanol\n",
    "        'CN',  # methylamine\n",
    "    ],\n",
    "    'test': [\n",
    "        'CCO',  # CONTAMINATION: same as train\n",
    "        'c1ccc(O)cc1',  # phenol\n",
    "        'CC(=O)OC',  # methyl acetate\n",
    "    ],\n",
    "    'validation': [\n",
    "        'CC(=O)O',  # CONTAMINATION: same as train\n",
    "        'CC(C)(C)O',  # tert-butanol\n",
    "        'c1cccnc1',  # pyridine\n",
    "    ]\n",
    "}\n",
    "\n",
    "detector = ContaminationDetector(similarity_threshold=0.8)\n",
    "\n",
    "# Run contamination analysis\n",
    "contamination_results = detector.detect_cross_dataset_leakage(example_datasets)\n",
    "\n",
    "print(\"\\nContamination Analysis Results:\")\n",
    "print(f\"Contamination severity: {contamination_results['summary']['contamination_severity']}\")\n",
    "print(f\"Total exact overlaps: {contamination_results['summary']['total_exact_overlaps']}\")\n",
    "\n",
    "print(\"\\nExact overlaps found:\")\n",
    "for overlap_key, overlap_data in contamination_results['exact_overlaps'].items():\n",
    "    if overlap_data['count'] > 0:\n",
    "        print(f\"  {overlap_key}: {overlap_data['count']} compounds ({overlap_data['percentage_of_first']:.1f}% of first dataset)\")\n",
    "        print(f\"    Examples: {overlap_data['overlapping_smiles']}\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "for i, rec in enumerate(contamination_results['summary']['recommendations'], 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "# Test temporal contamination detection\n",
    "print(f\"\\nTemporal Contamination Check:\")\n",
    "temporal_results = detector.detect_temporal_contamination(example_datasets['train'])\n",
    "print(f\"Suspicious compounds: {temporal_results['suspicious_count']}\")\n",
    "\n",
    "# Test vendor bias detection\n",
    "print(f\"\\nVendor Catalog Bias Check:\")\n",
    "bias_results = detector.detect_vendor_catalog_bias(example_datasets['train'])\n",
    "print(f\"Simple compounds flagged: {bias_results['flagged_simple']}/{bias_results['total_analyzed']}\")\n",
    "print(f\"Bias indicators detected: {any(bias_results['bias_indicators'].values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865eab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit_blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
